Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
 
Found train data with correct size
 
 
Found test data with correct size
 
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 65, 65, 3)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 63, 63, 16)        448       
_________________________________________________________________
batch_normalization_1 (Batch (None, 63, 63, 16)        64        
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 62, 62, 16)        1040      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 31, 31, 16)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 31, 31, 16)        64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 31, 31, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 29, 29, 16)        2320      
_________________________________________________________________
batch_normalization_3 (Batch (None, 29, 29, 16)        64        
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 28, 28, 16)        1040      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 14, 14, 16)        64        
_________________________________________________________________
dropout_2 (Dropout)          (None, 14, 14, 16)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 12, 12, 32)        4640      
_________________________________________________________________
batch_normalization_5 (Batch (None, 12, 12, 32)        128       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 11, 11, 32)        4128      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 5, 5, 32)          128       
_________________________________________________________________
dropout_3 (Dropout)          (None, 5, 5, 32)          0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 3, 3, 32)          9248      
_________________________________________________________________
batch_normalization_7 (Batch (None, 3, 3, 32)          128       
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 2, 2, 32)          4128      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 1, 1, 32)          0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 1, 1, 32)          128       
_________________________________________________________________
dropout_4 (Dropout)          (None, 1, 1, 32)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 32)                0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 32)                128       
_________________________________________________________________
dense_1 (Dense)              (None, 64)                2112      
_________________________________________________________________
dropout_5 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
dropout_6 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 12)                396       
=================================================================
Total params: 32,476
Trainable params: 32,028
Non-trainable params: 448
_________________________________________________________________
No saved trial for kfold.
Train on 3800 samples, validate on 950 samples
Epoch 1/500
2018-08-10 13:44:51.312663: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-08-10 13:44:51.312695: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
101s - loss: 2.5999 - acc: 0.0855 - val_loss: 2.4863 - val_acc: 0.0463
Epoch 2/500
97s - loss: 2.5235 - acc: 0.0989 - val_loss: 2.4772 - val_acc: 0.0537
Epoch 3/500
97s - loss: 2.4844 - acc: 0.1192 - val_loss: 2.4440 - val_acc: 0.1263
Epoch 4/500
97s - loss: 2.4267 - acc: 0.1511 - val_loss: 2.3749 - val_acc: 0.1821
Epoch 5/500
97s - loss: 2.3835 - acc: 0.1695 - val_loss: 2.2819 - val_acc: 0.2295
Epoch 6/500
97s - loss: 2.2970 - acc: 0.2095 - val_loss: 2.1956 - val_acc: 0.2779
Epoch 7/500
97s - loss: 2.2388 - acc: 0.2329 - val_loss: 2.1403 - val_acc: 0.2579
Epoch 8/500
97s - loss: 2.1696 - acc: 0.2584 - val_loss: 2.0492 - val_acc: 0.3221
Epoch 9/500
97s - loss: 2.1043 - acc: 0.2792 - val_loss: 1.9781 - val_acc: 0.3442
Epoch 10/500
97s - loss: 2.0276 - acc: 0.3071 - val_loss: 1.8886 - val_acc: 0.4063
Epoch 11/500
97s - loss: 1.9581 - acc: 0.3213 - val_loss: 1.7938 - val_acc: 0.3979
Epoch 12/500
97s - loss: 1.9176 - acc: 0.3366 - val_loss: 1.8325 - val_acc: 0.3442
Epoch 13/500
97s - loss: 1.8790 - acc: 0.3508 - val_loss: 1.7615 - val_acc: 0.3716
Epoch 14/500
97s - loss: 1.8482 - acc: 0.3603 - val_loss: 1.6644 - val_acc: 0.4389
Epoch 15/500
97s - loss: 1.7857 - acc: 0.3789 - val_loss: 1.6008 - val_acc: 0.4421
Epoch 16/500
97s - loss: 1.7554 - acc: 0.3876 - val_loss: 1.5852 - val_acc: 0.4632
Epoch 17/500
97s - loss: 1.7163 - acc: 0.4058 - val_loss: 1.5537 - val_acc: 0.4663
Epoch 18/500
97s - loss: 1.6591 - acc: 0.4124 - val_loss: 1.5116 - val_acc: 0.4663
Epoch 19/500
97s - loss: 1.6186 - acc: 0.4350 - val_loss: 1.4477 - val_acc: 0.5021
Epoch 20/500
97s - loss: 1.6084 - acc: 0.4405 - val_loss: 1.4983 - val_acc: 0.4832
Epoch 21/500
97s - loss: 1.5654 - acc: 0.4568 - val_loss: 1.3335 - val_acc: 0.5516
Epoch 22/500
97s - loss: 1.5399 - acc: 0.4679 - val_loss: 1.3781 - val_acc: 0.5179
Epoch 23/500
97s - loss: 1.5017 - acc: 0.4737 - val_loss: 1.3024 - val_acc: 0.5547
Epoch 24/500
97s - loss: 1.4897 - acc: 0.4803 - val_loss: 1.2292 - val_acc: 0.5916
Epoch 25/500
97s - loss: 1.4672 - acc: 0.4982 - val_loss: 1.2151 - val_acc: 0.5947
Epoch 26/500
97s - loss: 1.4363 - acc: 0.5026 - val_loss: 1.2248 - val_acc: 0.5779
Epoch 27/500
97s - loss: 1.4294 - acc: 0.5032 - val_loss: 1.1799 - val_acc: 0.6147
Epoch 28/500
97s - loss: 1.4061 - acc: 0.5166 - val_loss: 1.1488 - val_acc: 0.6074
Epoch 29/500
97s - loss: 1.3772 - acc: 0.5289 - val_loss: 1.1257 - val_acc: 0.6137
Epoch 30/500
97s - loss: 1.3382 - acc: 0.5400 - val_loss: 1.2313 - val_acc: 0.5716
Epoch 31/500
97s - loss: 1.3428 - acc: 0.5389 - val_loss: 1.0779 - val_acc: 0.6516
Epoch 32/500
97s - loss: 1.2904 - acc: 0.5532 - val_loss: 1.0656 - val_acc: 0.6484
Epoch 33/500
97s - loss: 1.3018 - acc: 0.5505 - val_loss: 1.0706 - val_acc: 0.6400
Epoch 34/500
98s - loss: 1.2790 - acc: 0.5713 - val_loss: 1.0093 - val_acc: 0.6611
Epoch 35/500
97s - loss: 1.2112 - acc: 0.5847 - val_loss: 0.9854 - val_acc: 0.6747
Epoch 36/500
96s - loss: 1.2398 - acc: 0.5789 - val_loss: 1.0264 - val_acc: 0.6484
Epoch 37/500
97s - loss: 1.2182 - acc: 0.5861 - val_loss: 0.9606 - val_acc: 0.6958
Epoch 38/500
97s - loss: 1.2376 - acc: 0.5745 - val_loss: 1.0422 - val_acc: 0.6484
Epoch 39/500
97s - loss: 1.1754 - acc: 0.6005 - val_loss: 0.9040 - val_acc: 0.7095
Epoch 40/500
96s - loss: 1.1877 - acc: 0.5963 - val_loss: 0.8954 - val_acc: 0.7137
Epoch 41/500
96s - loss: 1.1584 - acc: 0.5997 - val_loss: 0.9363 - val_acc: 0.6926
Epoch 42/500
96s - loss: 1.1152 - acc: 0.6187 - val_loss: 1.1187 - val_acc: 0.6095
Epoch 43/500
96s - loss: 1.1439 - acc: 0.6032 - val_loss: 0.9059 - val_acc: 0.6979
Epoch 44/500
96s - loss: 1.0953 - acc: 0.6276 - val_loss: 0.8786 - val_acc: 0.7158
Epoch 45/500
96s - loss: 1.0899 - acc: 0.6234 - val_loss: 0.8537 - val_acc: 0.7211
Epoch 46/500
96s - loss: 1.0802 - acc: 0.6289 - val_loss: 0.8907 - val_acc: 0.7126
Epoch 47/500
96s - loss: 1.0806 - acc: 0.6371 - val_loss: 0.8487 - val_acc: 0.7232
Epoch 48/500
96s - loss: 1.0853 - acc: 0.6342 - val_loss: 0.8471 - val_acc: 0.7242
Epoch 49/500
96s - loss: 1.0430 - acc: 0.6618 - val_loss: 0.8601 - val_acc: 0.7200
Epoch 50/500
96s - loss: 1.0322 - acc: 0.6503 - val_loss: 0.7885 - val_acc: 0.7389
Epoch 51/500
96s - loss: 1.0518 - acc: 0.6450 - val_loss: 0.8058 - val_acc: 0.7474
Epoch 52/500
96s - loss: 1.0154 - acc: 0.6574 - val_loss: 0.8294 - val_acc: 0.7316
Epoch 53/500
96s - loss: 1.0184 - acc: 0.6542 - val_loss: 0.8641 - val_acc: 0.6989
Epoch 54/500
96s - loss: 0.9945 - acc: 0.6608 - val_loss: 0.7765 - val_acc: 0.7484
Epoch 55/500
97s - loss: 0.9776 - acc: 0.6789 - val_loss: 0.7650 - val_acc: 0.7505
Epoch 56/500
96s - loss: 0.9284 - acc: 0.6889 - val_loss: 0.7494 - val_acc: 0.7568
Epoch 57/500
96s - loss: 0.9463 - acc: 0.6782 - val_loss: 0.7478 - val_acc: 0.7642
Epoch 58/500
96s - loss: 0.9354 - acc: 0.6937 - val_loss: 0.7067 - val_acc: 0.7695
Epoch 59/500
96s - loss: 0.9526 - acc: 0.6789 - val_loss: 0.8055 - val_acc: 0.7347
Epoch 60/500
96s - loss: 0.9217 - acc: 0.6900 - val_loss: 0.7664 - val_acc: 0.7537
Epoch 61/500
97s - loss: 0.9418 - acc: 0.6855 - val_loss: 0.7104 - val_acc: 0.7705
Epoch 62/500
96s - loss: 0.8844 - acc: 0.7079 - val_loss: 0.7281 - val_acc: 0.7684
Epoch 63/500
96s - loss: 0.8933 - acc: 0.7008 - val_loss: 0.7032 - val_acc: 0.7747
Epoch 64/500
96s - loss: 0.8847 - acc: 0.7008 - val_loss: 0.6713 - val_acc: 0.7842
Epoch 65/500
96s - loss: 0.8886 - acc: 0.7008 - val_loss: 0.6744 - val_acc: 0.7874
Epoch 66/500
96s - loss: 0.8750 - acc: 0.7037 - val_loss: 0.6706 - val_acc: 0.7863
Epoch 67/500
96s - loss: 0.8661 - acc: 0.7026 - val_loss: 0.7045 - val_acc: 0.7747
Epoch 68/500
97s - loss: 0.8449 - acc: 0.7234 - val_loss: 0.6517 - val_acc: 0.7916
Epoch 69/500
96s - loss: 0.8582 - acc: 0.7132 - val_loss: 0.7207 - val_acc: 0.7684
Epoch 70/500
96s - loss: 0.8324 - acc: 0.7218 - val_loss: 0.6446 - val_acc: 0.7947
Epoch 71/500
97s - loss: 0.8463 - acc: 0.7179 - val_loss: 0.6426 - val_acc: 0.7853
Epoch 72/500
97s - loss: 0.8201 - acc: 0.7253 - val_loss: 0.6242 - val_acc: 0.7947
Epoch 73/500
96s - loss: 0.8398 - acc: 0.7226 - val_loss: 0.6399 - val_acc: 0.7821
Epoch 74/500
96s - loss: 0.8105 - acc: 0.7289 - val_loss: 0.6308 - val_acc: 0.7895
Epoch 75/500
96s - loss: 0.8137 - acc: 0.7279 - val_loss: 0.6572 - val_acc: 0.7884
Epoch 76/500
95s - loss: 0.7990 - acc: 0.7234 - val_loss: 0.6204 - val_acc: 0.8032
Epoch 77/500
93s - loss: 0.8150 - acc: 0.7242 - val_loss: 0.6328 - val_acc: 0.7958
Epoch 78/500
92s - loss: 0.7927 - acc: 0.7326 - val_loss: 0.5730 - val_acc: 0.8147
Epoch 79/500
92s - loss: 0.7666 - acc: 0.7371 - val_loss: 0.6287 - val_acc: 0.7884
Epoch 80/500
92s - loss: 0.7802 - acc: 0.7421 - val_loss: 0.5945 - val_acc: 0.8011
Epoch 81/500
92s - loss: 0.7737 - acc: 0.7345 - val_loss: 0.5784 - val_acc: 0.8021
Epoch 82/500
92s - loss: 0.7583 - acc: 0.7508 - val_loss: 0.5775 - val_acc: 0.8105
Epoch 83/500
92s - loss: 0.7548 - acc: 0.7489 - val_loss: 0.7134 - val_acc: 0.7653
Epoch 84/500
92s - loss: 0.7609 - acc: 0.7492 - val_loss: 0.6045 - val_acc: 0.8074
Epoch 85/500
92s - loss: 0.7627 - acc: 0.7463 - val_loss: 0.6992 - val_acc: 0.7705
Epoch 86/500
92s - loss: 0.7463 - acc: 0.7487 - val_loss: 0.5792 - val_acc: 0.8147
Epoch 87/500

Epoch 00086: reducing learning rate to 9.99999974738e-06.
92s - loss: 0.7421 - acc: 0.7437 - val_loss: 0.6263 - val_acc: 0.7947
Epoch 88/500
92s - loss: 0.7262 - acc: 0.7545 - val_loss: 0.5601 - val_acc: 0.8105
Epoch 89/500
92s - loss: 0.7271 - acc: 0.7537 - val_loss: 0.5512 - val_acc: 0.8137
Epoch 90/500
92s - loss: 0.7278 - acc: 0.7542 - val_loss: 0.5499 - val_acc: 0.8158
Epoch 91/500
92s - loss: 0.7548 - acc: 0.7497 - val_loss: 0.5532 - val_acc: 0.8137
Epoch 92/500
92s - loss: 0.7077 - acc: 0.7595 - val_loss: 0.5526 - val_acc: 0.8168
Epoch 93/500
92s - loss: 0.6965 - acc: 0.7697 - val_loss: 0.5499 - val_acc: 0.8158
Epoch 94/500
92s - loss: 0.7177 - acc: 0.7658 - val_loss: 0.5491 - val_acc: 0.8137
Epoch 95/500
92s - loss: 0.7317 - acc: 0.7550 - val_loss: 0.5548 - val_acc: 0.8158
Epoch 96/500
92s - loss: 0.7277 - acc: 0.7642 - val_loss: 0.5465 - val_acc: 0.8179
Epoch 97/500
93s - loss: 0.7006 - acc: 0.7589 - val_loss: 0.5473 - val_acc: 0.8158
Epoch 98/500
92s - loss: 0.7114 - acc: 0.7671 - val_loss: 0.5407 - val_acc: 0.8179
Epoch 99/500
92s - loss: 0.7029 - acc: 0.7611 - val_loss: 0.5424 - val_acc: 0.8168
Epoch 100/500
92s - loss: 0.7163 - acc: 0.7579 - val_loss: 0.5430 - val_acc: 0.8147
Epoch 101/500
92s - loss: 0.6919 - acc: 0.7697 - val_loss: 0.5417 - val_acc: 0.8126
Epoch 102/500
92s - loss: 0.7120 - acc: 0.7576 - val_loss: 0.5439 - val_acc: 0.8189
Epoch 103/500
92s - loss: 0.7030 - acc: 0.7616 - val_loss: 0.5424 - val_acc: 0.8200
Epoch 104/500
92s - loss: 0.7014 - acc: 0.7684 - val_loss: 0.5422 - val_acc: 0.8189
Epoch 105/500
92s - loss: 0.7063 - acc: 0.7684 - val_loss: 0.5448 - val_acc: 0.8189
Epoch 106/500
92s - loss: 0.6920 - acc: 0.7684 - val_loss: 0.5379 - val_acc: 0.8168
Epoch 107/500
92s - loss: 0.7202 - acc: 0.7542 - val_loss: 0.5423 - val_acc: 0.8168
Epoch 108/500
92s - loss: 0.6904 - acc: 0.7684 - val_loss: 0.5401 - val_acc: 0.8211
Epoch 109/500
92s - loss: 0.7059 - acc: 0.7655 - val_loss: 0.5355 - val_acc: 0.8242
Epoch 110/500
92s - loss: 0.7073 - acc: 0.7597 - val_loss: 0.5389 - val_acc: 0.8242
Epoch 111/500
92s - loss: 0.6946 - acc: 0.7616 - val_loss: 0.5439 - val_acc: 0.8232
Epoch 112/500
92s - loss: 0.7036 - acc: 0.7653 - val_loss: 0.5425 - val_acc: 0.8232
Epoch 113/500
92s - loss: 0.6960 - acc: 0.7632 - val_loss: 0.5400 - val_acc: 0.8221
Epoch 114/500
92s - loss: 0.7189 - acc: 0.7626 - val_loss: 0.5364 - val_acc: 0.8189
Epoch 115/500
92s - loss: 0.7129 - acc: 0.7605 - val_loss: 0.5331 - val_acc: 0.8189
Epoch 116/500
92s - loss: 0.7053 - acc: 0.7624 - val_loss: 0.5374 - val_acc: 0.8189
Epoch 117/500
92s - loss: 0.6904 - acc: 0.7695 - val_loss: 0.5314 - val_acc: 0.8189
Epoch 118/500

Epoch 00117: reducing learning rate to 1e-06.
92s - loss: 0.7008 - acc: 0.7647 - val_loss: 0.5440 - val_acc: 0.8200
Epoch 119/500
92s - loss: 0.7025 - acc: 0.7553 - val_loss: 0.5396 - val_acc: 0.8189
Epoch 120/500
92s - loss: 0.6923 - acc: 0.7713 - val_loss: 0.5359 - val_acc: 0.8211
Epoch 121/500
92s - loss: 0.7213 - acc: 0.7558 - val_loss: 0.5371 - val_acc: 0.8179
Epoch 122/500
92s - loss: 0.6959 - acc: 0.7668 - val_loss: 0.5378 - val_acc: 0.8200
Epoch 123/500
92s - loss: 0.6717 - acc: 0.7755 - val_loss: 0.5340 - val_acc: 0.8200
Epoch 124/500
92s - loss: 0.6854 - acc: 0.7700 - val_loss: 0.5334 - val_acc: 0.8179
Epoch 125/500
92s - loss: 0.7132 - acc: 0.7668 - val_loss: 0.5350 - val_acc: 0.8179
Epoch 126/500
92s - loss: 0.6791 - acc: 0.7658 - val_loss: 0.5364 - val_acc: 0.8168
Epoch 127/500
92s - loss: 0.7051 - acc: 0.7608 - val_loss: 0.5347 - val_acc: 0.8179
Epoch 128/500
92s - loss: 0.6888 - acc: 0.7647 - val_loss: 0.5370 - val_acc: 0.8179
Epoch 129/500
92s - loss: 0.7044 - acc: 0.7711 - val_loss: 0.5356 - val_acc: 0.8189
Epoch 130/500
92s - loss: 0.7110 - acc: 0.7647 - val_loss: 0.5358 - val_acc: 0.8200
Epoch 131/500
92s - loss: 0.6874 - acc: 0.7682 - val_loss: 0.5337 - val_acc: 0.8200
Epoch 132/500
92s - loss: 0.7014 - acc: 0.7571 - val_loss: 0.5329 - val_acc: 0.8200
Epoch 133/500
92s - loss: 0.7002 - acc: 0.7645 - val_loss: 0.5356 - val_acc: 0.8200
Epoch 134/500
92s - loss: 0.6969 - acc: 0.7634 - val_loss: 0.5346 - val_acc: 0.8211
Epoch 135/500
92s - loss: 0.6889 - acc: 0.7729 - val_loss: 0.5345 - val_acc: 0.8211
Epoch 136/500
92s - loss: 0.7060 - acc: 0.7553 - val_loss: 0.5356 - val_acc: 0.8189
Epoch 137/500
92s - loss: 0.7032 - acc: 0.7621 - val_loss: 0.5344 - val_acc: 0.8179
Epoch 138/500
92s - loss: 0.6994 - acc: 0.7687 - val_loss: 0.5341 - val_acc: 0.8200
Epoch 139/500
92s - loss: 0.6966 - acc: 0.7663 - val_loss: 0.5373 - val_acc: 0.8189
Epoch 140/500
92s - loss: 0.7033 - acc: 0.7616 - val_loss: 0.5365 - val_acc: 0.8189
Epoch 141/500
92s - loss: 0.7031 - acc: 0.7682 - val_loss: 0.5348 - val_acc: 0.8211
Epoch 142/500
92s - loss: 0.6909 - acc: 0.7747 - val_loss: 0.5325 - val_acc: 0.8200
Epoch 143/500
92s - loss: 0.6905 - acc: 0.7737 - val_loss: 0.5324 - val_acc: 0.8200
Epoch 144/500
92s - loss: 0.7177 - acc: 0.7697 - val_loss: 0.5333 - val_acc: 0.8200
Epoch 145/500
92s - loss: 0.7143 - acc: 0.7600 - val_loss: 0.5314 - val_acc: 0.8189
Epoch 146/500
92s - loss: 0.6961 - acc: 0.7661 - val_loss: 0.5349 - val_acc: 0.8179
Epoch 147/500
92s - loss: 0.6966 - acc: 0.7616 - val_loss: 0.5371 - val_acc: 0.8221
Epoch 148/500
92s - loss: 0.6894 - acc: 0.7676 - val_loss: 0.5351 - val_acc: 0.8221
Epoch 149/500
92s - loss: 0.6995 - acc: 0.7637 - val_loss: 0.5372 - val_acc: 0.8221
Epoch 150/500
92s - loss: 0.6973 - acc: 0.7692 - val_loss: 0.5338 - val_acc: 0.8200
Epoch 151/500
92s - loss: 0.7332 - acc: 0.7497 - val_loss: 0.5370 - val_acc: 0.8189
Epoch 152/500
92s - loss: 0.6932 - acc: 0.7597 - val_loss: 0.5360 - val_acc: 0.8211
Epoch 153/500
92s - loss: 0.6855 - acc: 0.7708 - val_loss: 0.5348 - val_acc: 0.8211
Epoch 154/500
92s - loss: 0.6919 - acc: 0.7576 - val_loss: 0.5330 - val_acc: 0.8200
Epoch 155/500
92s - loss: 0.7221 - acc: 0.7576 - val_loss: 0.5370 - val_acc: 0.8200
Epoch 156/500
92s - loss: 0.7020 - acc: 0.7587 - val_loss: 0.5368 - val_acc: 0.8200
Epoch 157/500
92s - loss: 0.6798 - acc: 0.7697 - val_loss: 0.5341 - val_acc: 0.8179
Epoch 158/500
92s - loss: 0.6938 - acc: 0.7611 - val_loss: 0.5336 - val_acc: 0.8189
Epoch 159/500
92s - loss: 0.7032 - acc: 0.7687 - val_loss: 0.5338 - val_acc: 0.8168
Epoch 160/500
92s - loss: 0.6823 - acc: 0.7703 - val_loss: 0.5369 - val_acc: 0.8200
Epoch 161/500
92s - loss: 0.6940 - acc: 0.7708 - val_loss: 0.5356 - val_acc: 0.8211
Epoch 162/500
92s - loss: 0.6958 - acc: 0.7645 - val_loss: 0.5332 - val_acc: 0.8221
Epoch 163/500
92s - loss: 0.7084 - acc: 0.7629 - val_loss: 0.5349 - val_acc: 0.8200
Epoch 164/500
92s - loss: 0.6731 - acc: 0.7708 - val_loss: 0.5366 - val_acc: 0.8200
Epoch 165/500
92s - loss: 0.6764 - acc: 0.7695 - val_loss: 0.5365 - val_acc: 0.8221
Epoch 166/500
92s - loss: 0.6802 - acc: 0.7837 - val_loss: 0.5322 - val_acc: 0.8211
Epoch 167/500
92s - loss: 0.6964 - acc: 0.7721 - val_loss: 0.5343 - val_acc: 0.8211
Epoch 168/500
92s - loss: 0.6945 - acc: 0.7721 - val_loss: 0.5365 - val_acc: 0.8211
Epoch 169/500
93s - loss: 0.6636 - acc: 0.7761 - val_loss: 0.5344 - val_acc: 0.8200
Epoch 170/500
93s - loss: 0.6881 - acc: 0.7684 - val_loss: 0.5357 - val_acc: 0.8221
Epoch 171/500
92s - loss: 0.6805 - acc: 0.7737 - val_loss: 0.5359 - val_acc: 0.8221
Epoch 172/500
92s - loss: 0.7082 - acc: 0.7605 - val_loss: 0.5404 - val_acc: 0.8200
Epoch 173/500
92s - loss: 0.6990 - acc: 0.7729 - val_loss: 0.5373 - val_acc: 0.8189
Epoch 174/500
92s - loss: 0.7162 - acc: 0.7653 - val_loss: 0.5316 - val_acc: 0.8211
Epoch 175/500
92s - loss: 0.7070 - acc: 0.7647 - val_loss: 0.5353 - val_acc: 0.8221
Epoch 176/500
93s - loss: 0.6898 - acc: 0.7697 - val_loss: 0.5343 - val_acc: 0.8200
Epoch 177/500
93s - loss: 0.7062 - acc: 0.7724 - val_loss: 0.5337 - val_acc: 0.8200
Epoch 178/500
93s - loss: 0.7096 - acc: 0.7568 - val_loss: 0.5367 - val_acc: 0.8179
Epoch 179/500
93s - loss: 0.6794 - acc: 0.7729 - val_loss: 0.5350 - val_acc: 0.8221
Epoch 180/500
93s - loss: 0.6827 - acc: 0.7692 - val_loss: 0.5343 - val_acc: 0.8189
Epoch 181/500
93s - loss: 0.6945 - acc: 0.7647 - val_loss: 0.5335 - val_acc: 0.8200
Epoch 182/500
93s - loss: 0.7029 - acc: 0.7737 - val_loss: 0.5305 - val_acc: 0.8232
Epoch 183/500
93s - loss: 0.6815 - acc: 0.7803 - val_loss: 0.5337 - val_acc: 0.8189
Epoch 184/500
93s - loss: 0.6926 - acc: 0.7771 - val_loss: 0.5337 - val_acc: 0.8221
Epoch 185/500
93s - loss: 0.6802 - acc: 0.7700 - val_loss: 0.5326 - val_acc: 0.8232
Epoch 186/500
93s - loss: 0.7063 - acc: 0.7589 - val_loss: 0.5363 - val_acc: 0.8200
Epoch 187/500
93s - loss: 0.6770 - acc: 0.7668 - val_loss: 0.5367 - val_acc: 0.8200
Epoch 188/500
93s - loss: 0.7190 - acc: 0.7605 - val_loss: 0.5325 - val_acc: 0.8200
Epoch 189/500
93s - loss: 0.6920 - acc: 0.7653 - val_loss: 0.5360 - val_acc: 0.8189
Epoch 190/500
93s - loss: 0.6799 - acc: 0.7695 - val_loss: 0.5348 - val_acc: 0.8189
Epoch 191/500
93s - loss: 0.6961 - acc: 0.7621 - val_loss: 0.5337 - val_acc: 0.8200
Epoch 192/500
93s - loss: 0.6891 - acc: 0.7650 - val_loss: 0.5343 - val_acc: 0.8179
Epoch 193/500
93s - loss: 0.6793 - acc: 0.7800 - val_loss: 0.5325 - val_acc: 0.8179
Epoch 194/500
93s - loss: 0.6943 - acc: 0.7713 - val_loss: 0.5323 - val_acc: 0.8189
Epoch 195/500
93s - loss: 0.7015 - acc: 0.7647 - val_loss: 0.5318 - val_acc: 0.8211
Epoch 196/500
93s - loss: 0.6987 - acc: 0.7708 - val_loss: 0.5336 - val_acc: 0.8179
Epoch 197/500
93s - loss: 0.6814 - acc: 0.7753 - val_loss: 0.5346 - val_acc: 0.8200
Epoch 198/500
93s - loss: 0.6808 - acc: 0.7663 - val_loss: 0.5338 - val_acc: 0.8179
Epoch 199/500
93s - loss: 0.6532 - acc: 0.7800 - val_loss: 0.5338 - val_acc: 0.8211
Epoch 200/500
93s - loss: 0.6874 - acc: 0.7729 - val_loss: 0.5326 - val_acc: 0.8200
Epoch 201/500
93s - loss: 0.6789 - acc: 0.7747 - val_loss: 0.5324 - val_acc: 0.8189
Epoch 202/500
93s - loss: 0.6837 - acc: 0.7739 - val_loss: 0.5345 - val_acc: 0.8200
Epoch 203/500
91s - loss: 0.6913 - acc: 0.7705 - val_loss: 0.5319 - val_acc: 0.8179
Epoch 204/500
91s - loss: 0.6861 - acc: 0.7716 - val_loss: 0.5321 - val_acc: 0.8200
Epoch 205/500
91s - loss: 0.6976 - acc: 0.7697 - val_loss: 0.5344 - val_acc: 0.8200
Epoch 206/500
91s - loss: 0.6975 - acc: 0.7647 - val_loss: 0.5312 - val_acc: 0.8211
Epoch 207/500
91s - loss: 0.6555 - acc: 0.7795 - val_loss: 0.5323 - val_acc: 0.8211
Epoch 208/500
91s - loss: 0.6942 - acc: 0.7737 - val_loss: 0.5324 - val_acc: 0.8179
Epoch 209/500
91s - loss: 0.6913 - acc: 0.7700 - val_loss: 0.5305 - val_acc: 0.8211
Epoch 210/500
91s - loss: 0.6938 - acc: 0.7600 - val_loss: 0.5325 - val_acc: 0.8200
Epoch 211/500
91s - loss: 0.6953 - acc: 0.7603 - val_loss: 0.5309 - val_acc: 0.8211
Epoch 212/500
91s - loss: 0.7076 - acc: 0.7695 - val_loss: 0.5310 - val_acc: 0.8211
Epoch 213/500
91s - loss: 0.7066 - acc: 0.7555 - val_loss: 0.5338 - val_acc: 0.8211
Epoch 214/500
91s - loss: 0.6822 - acc: 0.7705 - val_loss: 0.5293 - val_acc: 0.8189
Epoch 215/500
91s - loss: 0.6777 - acc: 0.7655 - val_loss: 0.5335 - val_acc: 0.8189
Epoch 216/500
91s - loss: 0.7024 - acc: 0.7637 - val_loss: 0.5293 - val_acc: 0.8211
Epoch 217/500
91s - loss: 0.6823 - acc: 0.7632 - val_loss: 0.5321 - val_acc: 0.8200
Epoch 218/500
91s - loss: 0.7162 - acc: 0.7616 - val_loss: 0.5319 - val_acc: 0.8211
Epoch 219/500
91s - loss: 0.7113 - acc: 0.7603 - val_loss: 0.5316 - val_acc: 0.8200
Epoch 220/500
91s - loss: 0.7167 - acc: 0.7566 - val_loss: 0.5317 - val_acc: 0.8200
Epoch 221/500
91s - loss: 0.7003 - acc: 0.7647 - val_loss: 0.5283 - val_acc: 0.8189
Epoch 222/500
91s - loss: 0.6631 - acc: 0.7842 - val_loss: 0.5331 - val_acc: 0.8179
Epoch 223/500
91s - loss: 0.6802 - acc: 0.7745 - val_loss: 0.5344 - val_acc: 0.8200
Epoch 224/500
91s - loss: 0.6751 - acc: 0.7745 - val_loss: 0.5301 - val_acc: 0.8179
Epoch 225/500
91s - loss: 0.6956 - acc: 0.7692 - val_loss: 0.5300 - val_acc: 0.8189
Epoch 226/500
91s - loss: 0.6740 - acc: 0.7732 - val_loss: 0.5328 - val_acc: 0.8200
Epoch 227/500
91s - loss: 0.6743 - acc: 0.7745 - val_loss: 0.5333 - val_acc: 0.8211
Epoch 228/500
91s - loss: 0.6933 - acc: 0.7637 - val_loss: 0.5362 - val_acc: 0.8221
Epoch 229/500
91s - loss: 0.6801 - acc: 0.7718 - val_loss: 0.5335 - val_acc: 0.8200
Epoch 230/500
91s - loss: 0.6898 - acc: 0.7771 - val_loss: 0.5319 - val_acc: 0.8189
Epoch 231/500
91s - loss: 0.6953 - acc: 0.7650 - val_loss: 0.5333 - val_acc: 0.8200
Epoch 232/500
91s - loss: 0.6816 - acc: 0.7724 - val_loss: 0.5321 - val_acc: 0.8168
Epoch 233/500
91s - loss: 0.7024 - acc: 0.7608 - val_loss: 0.5294 - val_acc: 0.8189
Epoch 234/500
91s - loss: 0.7006 - acc: 0.7713 - val_loss: 0.5295 - val_acc: 0.8189
Epoch 235/500
91s - loss: 0.6870 - acc: 0.7637 - val_loss: 0.5315 - val_acc: 0.8200
Epoch 236/500
91s - loss: 0.6707 - acc: 0.7837 - val_loss: 0.5317 - val_acc: 0.8200
Epoch 237/500
91s - loss: 0.6791 - acc: 0.7787 - val_loss: 0.5311 - val_acc: 0.8189
Epoch 238/500
91s - loss: 0.6892 - acc: 0.7689 - val_loss: 0.5296 - val_acc: 0.8179
Epoch 239/500
91s - loss: 0.6874 - acc: 0.7697 - val_loss: 0.5305 - val_acc: 0.8200
Epoch 240/500
91s - loss: 0.6913 - acc: 0.7671 - val_loss: 0.5292 - val_acc: 0.8211
Epoch 241/500
91s - loss: 0.6820 - acc: 0.7745 - val_loss: 0.5300 - val_acc: 0.8211
Epoch 242/500
91s - loss: 0.6821 - acc: 0.7697 - val_loss: 0.5318 - val_acc: 0.8189
Epoch 243/500
91s - loss: 0.7009 - acc: 0.7645 - val_loss: 0.5303 - val_acc: 0.8211
Epoch 244/500
91s - loss: 0.6811 - acc: 0.7658 - val_loss: 0.5304 - val_acc: 0.8168
Epoch 245/500
91s - loss: 0.7061 - acc: 0.7568 - val_loss: 0.5330 - val_acc: 0.8168
Epoch 246/500
91s - loss: 0.6892 - acc: 0.7658 - val_loss: 0.5314 - val_acc: 0.8168
Epoch 247/500
91s - loss: 0.7043 - acc: 0.7655 - val_loss: 0.5296 - val_acc: 0.8200
Epoch 248/500
91s - loss: 0.6826 - acc: 0.7713 - val_loss: 0.5319 - val_acc: 0.8189
Epoch 249/500
91s - loss: 0.6682 - acc: 0.7787 - val_loss: 0.5361 - val_acc: 0.8200
Epoch 250/500
91s - loss: 0.6607 - acc: 0.7787 - val_loss: 0.5320 - val_acc: 0.8189
Epoch 251/500
91s - loss: 0.6718 - acc: 0.7789 - val_loss: 0.5329 - val_acc: 0.8179
Epoch 252/500
91s - loss: 0.6762 - acc: 0.7753 - val_loss: 0.5326 - val_acc: 0.8189
Epoch 253/500
91s - loss: 0.6904 - acc: 0.7761 - val_loss: 0.5342 - val_acc: 0.8232
Epoch 254/500
91s - loss: 0.7098 - acc: 0.7668 - val_loss: 0.5314 - val_acc: 0.8189
Epoch 255/500
91s - loss: 0.6750 - acc: 0.7718 - val_loss: 0.5309 - val_acc: 0.8200
Epoch 256/500
91s - loss: 0.6846 - acc: 0.7655 - val_loss: 0.5319 - val_acc: 0.8200
Epoch 257/500
91s - loss: 0.6556 - acc: 0.7837 - val_loss: 0.5289 - val_acc: 0.8200
Epoch 258/500
91s - loss: 0.6785 - acc: 0.7705 - val_loss: 0.5295 - val_acc: 0.8211
Epoch 259/500
92s - loss: 0.6914 - acc: 0.7703 - val_loss: 0.5330 - val_acc: 0.8189
Epoch 260/500
92s - loss: 0.6789 - acc: 0.7842 - val_loss: 0.5291 - val_acc: 0.8200
Epoch 261/500
91s - loss: 0.6827 - acc: 0.7732 - val_loss: 0.5323 - val_acc: 0.8200
Epoch 262/500
91s - loss: 0.6864 - acc: 0.7697 - val_loss: 0.5294 - val_acc: 0.8200
Epoch 263/500
91s - loss: 0.6761 - acc: 0.7739 - val_loss: 0.5317 - val_acc: 0.8200
Epoch 264/500
91s - loss: 0.6910 - acc: 0.7676 - val_loss: 0.5320 - val_acc: 0.8200
Epoch 265/500
91s - loss: 0.6856 - acc: 0.7661 - val_loss: 0.5322 - val_acc: 0.8189
Epoch 266/500
91s - loss: 0.6977 - acc: 0.7668 - val_loss: 0.5289 - val_acc: 0.8179
Epoch 267/500
91s - loss: 0.6848 - acc: 0.7618 - val_loss: 0.5330 - val_acc: 0.8200
Epoch 268/500
91s - loss: 0.6773 - acc: 0.7776 - val_loss: 0.5307 - val_acc: 0.8200
Epoch 269/500
91s - loss: 0.6870 - acc: 0.7742 - val_loss: 0.5302 - val_acc: 0.8221
Epoch 270/500
91s - loss: 0.6859 - acc: 0.7666 - val_loss: 0.5335 - val_acc: 0.8189
Epoch 271/500
91s - loss: 0.6884 - acc: 0.7692 - val_loss: 0.5291 - val_acc: 0.8200
Epoch 272/500
91s - loss: 0.7050 - acc: 0.7603 - val_loss: 0.5303 - val_acc: 0.8211
Epoch 273/500
91s - loss: 0.7052 - acc: 0.7603 - val_loss: 0.5303 - val_acc: 0.8211
Epoch 274/500
91s - loss: 0.6856 - acc: 0.7779 - val_loss: 0.5292 - val_acc: 0.8211
Epoch 275/500
91s - loss: 0.6774 - acc: 0.7734 - val_loss: 0.5268 - val_acc: 0.8211
Epoch 276/500
91s - loss: 0.6895 - acc: 0.7682 - val_loss: 0.5291 - val_acc: 0.8221
Epoch 277/500
91s - loss: 0.7030 - acc: 0.7608 - val_loss: 0.5294 - val_acc: 0.8200
Epoch 278/500
91s - loss: 0.7027 - acc: 0.7687 - val_loss: 0.5281 - val_acc: 0.8221
Epoch 279/500
91s - loss: 0.7098 - acc: 0.7663 - val_loss: 0.5299 - val_acc: 0.8200
Epoch 280/500
91s - loss: 0.6796 - acc: 0.7747 - val_loss: 0.5312 - val_acc: 0.8189
Epoch 281/500
91s - loss: 0.6824 - acc: 0.7776 - val_loss: 0.5292 - val_acc: 0.8189
Epoch 282/500
91s - loss: 0.6997 - acc: 0.7689 - val_loss: 0.5307 - val_acc: 0.8200
Epoch 283/500
91s - loss: 0.7009 - acc: 0.7682 - val_loss: 0.5301 - val_acc: 0.8179
Epoch 284/500
91s - loss: 0.6926 - acc: 0.7658 - val_loss: 0.5304 - val_acc: 0.8211
Epoch 285/500
91s - loss: 0.6666 - acc: 0.7800 - val_loss: 0.5304 - val_acc: 0.8189
Epoch 286/500
91s - loss: 0.6518 - acc: 0.7821 - val_loss: 0.5314 - val_acc: 0.8179
Epoch 287/500
91s - loss: 0.6812 - acc: 0.7742 - val_loss: 0.5318 - val_acc: 0.8211
Epoch 288/500
91s - loss: 0.6967 - acc: 0.7679 - val_loss: 0.5312 - val_acc: 0.8189
Epoch 289/500
91s - loss: 0.6794 - acc: 0.7729 - val_loss: 0.5287 - val_acc: 0.8189
Epoch 290/500
91s - loss: 0.7077 - acc: 0.7718 - val_loss: 0.5315 - val_acc: 0.8189
Epoch 291/500
91s - loss: 0.6885 - acc: 0.7676 - val_loss: 0.5298 - val_acc: 0.8211
Epoch 292/500
91s - loss: 0.6740 - acc: 0.7742 - val_loss: 0.5317 - val_acc: 0.8189
Epoch 293/500
91s - loss: 0.6897 - acc: 0.7624 - val_loss: 0.5303 - val_acc: 0.8232
Epoch 294/500
91s - loss: 0.6964 - acc: 0.7671 - val_loss: 0.5302 - val_acc: 0.8211
Epoch 295/500
91s - loss: 0.6958 - acc: 0.7647 - val_loss: 0.5308 - val_acc: 0.8211
Epoch 296/500
91s - loss: 0.6777 - acc: 0.7692 - val_loss: 0.5312 - val_acc: 0.8189
Epoch 297/500
91s - loss: 0.6611 - acc: 0.7782 - val_loss: 0.5311 - val_acc: 0.8189
Epoch 298/500
91s - loss: 0.7116 - acc: 0.7642 - val_loss: 0.5303 - val_acc: 0.8189
Epoch 299/500
91s - loss: 0.7126 - acc: 0.7579 - val_loss: 0.5286 - val_acc: 0.8211
Epoch 300/500
91s - loss: 0.6841 - acc: 0.7621 - val_loss: 0.5302 - val_acc: 0.8221
Epoch 301/500
91s - loss: 0.6768 - acc: 0.7792 - val_loss: 0.5284 - val_acc: 0.8189
Epoch 302/500
91s - loss: 0.6771 - acc: 0.7729 - val_loss: 0.5316 - val_acc: 0.8221
Epoch 303/500
91s - loss: 0.6834 - acc: 0.7708 - val_loss: 0.5292 - val_acc: 0.8221
Epoch 304/500
91s - loss: 0.6749 - acc: 0.7763 - val_loss: 0.5305 - val_acc: 0.8211
Epoch 305/500
91s - loss: 0.6697 - acc: 0.7763 - val_loss: 0.5282 - val_acc: 0.8211
Epoch 306/500
91s - loss: 0.7029 - acc: 0.7624 - val_loss: 0.5306 - val_acc: 0.8211
Epoch 307/500
91s - loss: 0.6734 - acc: 0.7724 - val_loss: 0.5286 - val_acc: 0.8200
Epoch 308/500
91s - loss: 0.6722 - acc: 0.7739 - val_loss: 0.5294 - val_acc: 0.8211
Epoch 309/500
91s - loss: 0.6899 - acc: 0.7695 - val_loss: 0.5270 - val_acc: 0.8232
Epoch 310/500
91s - loss: 0.6744 - acc: 0.7705 - val_loss: 0.5299 - val_acc: 0.8211
Epoch 311/500
91s - loss: 0.7139 - acc: 0.7605 - val_loss: 0.5319 - val_acc: 0.8200
Epoch 312/500
92s - loss: 0.6990 - acc: 0.7632 - val_loss: 0.5325 - val_acc: 0.8189
Epoch 313/500
91s - loss: 0.6882 - acc: 0.7739 - val_loss: 0.5333 - val_acc: 0.8221
Epoch 314/500
91s - loss: 0.7162 - acc: 0.7576 - val_loss: 0.5310 - val_acc: 0.8200
Epoch 315/500
91s - loss: 0.6879 - acc: 0.7766 - val_loss: 0.5259 - val_acc: 0.8200
Epoch 316/500
91s - loss: 0.6928 - acc: 0.7721 - val_loss: 0.5289 - val_acc: 0.8211
Epoch 317/500
91s - loss: 0.6869 - acc: 0.7695 - val_loss: 0.5346 - val_acc: 0.8200
Epoch 318/500
91s - loss: 0.6834 - acc: 0.7763 - val_loss: 0.5308 - val_acc: 0.8221
Epoch 319/500
91s - loss: 0.6516 - acc: 0.7805 - val_loss: 0.5342 - val_acc: 0.8242
Epoch 320/500
91s - loss: 0.7045 - acc: 0.7663 - val_loss: 0.5283 - val_acc: 0.8221
Epoch 321/500
91s - loss: 0.6786 - acc: 0.7645 - val_loss: 0.5269 - val_acc: 0.8221
Epoch 322/500
91s - loss: 0.7153 - acc: 0.7600 - val_loss: 0.5270 - val_acc: 0.8211
Epoch 323/500
91s - loss: 0.6807 - acc: 0.7758 - val_loss: 0.5287 - val_acc: 0.8200
Epoch 324/500
91s - loss: 0.6834 - acc: 0.7724 - val_loss: 0.5306 - val_acc: 0.8189
Epoch 325/500
91s - loss: 0.6588 - acc: 0.7758 - val_loss: 0.5290 - val_acc: 0.8200
Epoch 326/500
91s - loss: 0.7250 - acc: 0.7563 - val_loss: 0.5300 - val_acc: 0.8200
Epoch 327/500
91s - loss: 0.6878 - acc: 0.7700 - val_loss: 0.5283 - val_acc: 0.8200
Epoch 328/500
91s - loss: 0.6984 - acc: 0.7692 - val_loss: 0.5304 - val_acc: 0.8211
Epoch 329/500
91s - loss: 0.6803 - acc: 0.7713 - val_loss: 0.5280 - val_acc: 0.8211
Epoch 330/500
91s - loss: 0.6647 - acc: 0.7824 - val_loss: 0.5261 - val_acc: 0.8211
Epoch 331/500
91s - loss: 0.6750 - acc: 0.7784 - val_loss: 0.5282 - val_acc: 0.8211
Epoch 332/500
91s - loss: 0.6827 - acc: 0.7668 - val_loss: 0.5272 - val_acc: 0.8200
Epoch 333/500
91s - loss: 0.7007 - acc: 0.7703 - val_loss: 0.5278 - val_acc: 0.8211
Epoch 334/500
91s - loss: 0.6725 - acc: 0.7787 - val_loss: 0.5268 - val_acc: 0.8211
Epoch 335/500
91s - loss: 0.6859 - acc: 0.7695 - val_loss: 0.5278 - val_acc: 0.8189
Epoch 336/500
91s - loss: 0.7113 - acc: 0.7666 - val_loss: 0.5268 - val_acc: 0.8232
Epoch 337/500
91s - loss: 0.6979 - acc: 0.7700 - val_loss: 0.5272 - val_acc: 0.8200
Epoch 338/500
91s - loss: 0.6863 - acc: 0.7755 - val_loss: 0.5275 - val_acc: 0.8211
Epoch 339/500
91s - loss: 0.6808 - acc: 0.7737 - val_loss: 0.5297 - val_acc: 0.8211
Epoch 340/500
91s - loss: 0.6870 - acc: 0.7679 - val_loss: 0.5287 - val_acc: 0.8211
Epoch 341/500
91s - loss: 0.6777 - acc: 0.7732 - val_loss: 0.5292 - val_acc: 0.8211
Epoch 342/500
91s - loss: 0.7046 - acc: 0.7666 - val_loss: 0.5309 - val_acc: 0.8200
Epoch 343/500
91s - loss: 0.6801 - acc: 0.7655 - val_loss: 0.5292 - val_acc: 0.8200
Epoch 344/500
91s - loss: 0.6867 - acc: 0.7700 - val_loss: 0.5256 - val_acc: 0.8211
Epoch 345/500
91s - loss: 0.6788 - acc: 0.7732 - val_loss: 0.5316 - val_acc: 0.8200
Epoch 346/500
91s - loss: 0.6794 - acc: 0.7695 - val_loss: 0.5301 - val_acc: 0.8189
Epoch 347/500
91s - loss: 0.6861 - acc: 0.7713 - val_loss: 0.5277 - val_acc: 0.8211
Epoch 348/500
91s - loss: 0.6848 - acc: 0.7679 - val_loss: 0.5303 - val_acc: 0.8211
Epoch 349/500
91s - loss: 0.6914 - acc: 0.7682 - val_loss: 0.5310 - val_acc: 0.8200
Epoch 350/500
91s - loss: 0.6945 - acc: 0.7684 - val_loss: 0.5263 - val_acc: 0.8200
Epoch 351/500
91s - loss: 0.7026 - acc: 0.7692 - val_loss: 0.5288 - val_acc: 0.8232
Epoch 352/500
91s - loss: 0.6846 - acc: 0.7682 - val_loss: 0.5277 - val_acc: 0.8179
Epoch 353/500
91s - loss: 0.6596 - acc: 0.7795 - val_loss: 0.5308 - val_acc: 0.8221
Epoch 354/500
91s - loss: 0.6761 - acc: 0.7703 - val_loss: 0.5305 - val_acc: 0.8200
Epoch 355/500
91s - loss: 0.6852 - acc: 0.7684 - val_loss: 0.5318 - val_acc: 0.8211
Epoch 356/500
91s - loss: 0.6825 - acc: 0.7705 - val_loss: 0.5288 - val_acc: 0.8221
Epoch 357/500
91s - loss: 0.6861 - acc: 0.7808 - val_loss: 0.5249 - val_acc: 0.8200
Epoch 358/500
91s - loss: 0.6785 - acc: 0.7697 - val_loss: 0.5268 - val_acc: 0.8221
Epoch 359/500
91s - loss: 0.6625 - acc: 0.7832 - val_loss: 0.5289 - val_acc: 0.8189
Epoch 360/500
91s - loss: 0.6883 - acc: 0.7666 - val_loss: 0.5285 - val_acc: 0.8200
Epoch 361/500
91s - loss: 0.6753 - acc: 0.7776 - val_loss: 0.5278 - val_acc: 0.8189
Epoch 362/500
91s - loss: 0.6885 - acc: 0.7684 - val_loss: 0.5266 - val_acc: 0.8211
Epoch 363/500
91s - loss: 0.6775 - acc: 0.7708 - val_loss: 0.5304 - val_acc: 0.8211
Epoch 364/500
91s - loss: 0.6820 - acc: 0.7676 - val_loss: 0.5281 - val_acc: 0.8221
Epoch 365/500
91s - loss: 0.7026 - acc: 0.7666 - val_loss: 0.5285 - val_acc: 0.8221
Epoch 366/500
91s - loss: 0.6868 - acc: 0.7729 - val_loss: 0.5265 - val_acc: 0.8211
Epoch 367/500
91s - loss: 0.7034 - acc: 0.7682 - val_loss: 0.5271 - val_acc: 0.8200
Epoch 368/500
91s - loss: 0.6773 - acc: 0.7745 - val_loss: 0.5235 - val_acc: 0.8211
Epoch 369/500
91s - loss: 0.6893 - acc: 0.7721 - val_loss: 0.5268 - val_acc: 0.8211
Epoch 370/500
91s - loss: 0.7091 - acc: 0.7611 - val_loss: 0.5274 - val_acc: 0.8200
Epoch 371/500
91s - loss: 0.6621 - acc: 0.7805 - val_loss: 0.5266 - val_acc: 0.8200
Epoch 372/500
91s - loss: 0.6851 - acc: 0.7700 - val_loss: 0.5246 - val_acc: 0.8211
Epoch 373/500
91s - loss: 0.6695 - acc: 0.7718 - val_loss: 0.5287 - val_acc: 0.8232
Epoch 374/500
91s - loss: 0.6891 - acc: 0.7726 - val_loss: 0.5294 - val_acc: 0.8221
Epoch 375/500
91s - loss: 0.6812 - acc: 0.7703 - val_loss: 0.5284 - val_acc: 0.8200
Epoch 376/500
91s - loss: 0.6579 - acc: 0.7747 - val_loss: 0.5304 - val_acc: 0.8211
Epoch 377/500
91s - loss: 0.6853 - acc: 0.7697 - val_loss: 0.5276 - val_acc: 0.8211
Epoch 378/500
91s - loss: 0.6799 - acc: 0.7692 - val_loss: 0.5311 - val_acc: 0.8189
Epoch 379/500
91s - loss: 0.6660 - acc: 0.7753 - val_loss: 0.5260 - val_acc: 0.8211
Epoch 380/500
91s - loss: 0.6947 - acc: 0.7726 - val_loss: 0.5272 - val_acc: 0.8200
Epoch 381/500
91s - loss: 0.6664 - acc: 0.7761 - val_loss: 0.5291 - val_acc: 0.8200
Epoch 382/500
91s - loss: 0.6849 - acc: 0.7687 - val_loss: 0.5263 - val_acc: 0.8200
Epoch 383/500
91s - loss: 0.6845 - acc: 0.7768 - val_loss: 0.5288 - val_acc: 0.8211
Epoch 384/500
91s - loss: 0.6576 - acc: 0.7782 - val_loss: 0.5266 - val_acc: 0.8211
Epoch 385/500
91s - loss: 0.6795 - acc: 0.7711 - val_loss: 0.5263 - val_acc: 0.8200
Epoch 386/500
91s - loss: 0.6900 - acc: 0.7784 - val_loss: 0.5245 - val_acc: 0.8211
Epoch 387/500
91s - loss: 0.7081 - acc: 0.7576 - val_loss: 0.5258 - val_acc: 0.8200
Epoch 388/500
91s - loss: 0.6687 - acc: 0.7795 - val_loss: 0.5296 - val_acc: 0.8189
Epoch 389/500
91s - loss: 0.6802 - acc: 0.7726 - val_loss: 0.5262 - val_acc: 0.8211
Epoch 390/500
91s - loss: 0.6732 - acc: 0.7750 - val_loss: 0.5255 - val_acc: 0.8211
Epoch 391/500
91s - loss: 0.6977 - acc: 0.7711 - val_loss: 0.5260 - val_acc: 0.8221
Epoch 392/500
91s - loss: 0.6559 - acc: 0.7724 - val_loss: 0.5256 - val_acc: 0.8211
Epoch 393/500
91s - loss: 0.6981 - acc: 0.7655 - val_loss: 0.5240 - val_acc: 0.8211
Epoch 394/500
91s - loss: 0.6756 - acc: 0.7742 - val_loss: 0.5243 - val_acc: 0.8232
Epoch 395/500
91s - loss: 0.6616 - acc: 0.7726 - val_loss: 0.5237 - val_acc: 0.8200
Epoch 396/500
91s - loss: 0.6964 - acc: 0.7682 - val_loss: 0.5253 - val_acc: 0.8211
Epoch 397/500
91s - loss: 0.6828 - acc: 0.7739 - val_loss: 0.5266 - val_acc: 0.8221
Epoch 398/500
91s - loss: 0.6685 - acc: 0.7700 - val_loss: 0.5258 - val_acc: 0.8221
Epoch 399/500
91s - loss: 0.6619 - acc: 0.7768 - val_loss: 0.5262 - val_acc: 0.8211
Epoch 400/500
91s - loss: 0.6784 - acc: 0.7724 - val_loss: 0.5239 - val_acc: 0.8221
Epoch 401/500
91s - loss: 0.6709 - acc: 0.7750 - val_loss: 0.5266 - val_acc: 0.8232
Epoch 402/500
91s - loss: 0.6805 - acc: 0.7716 - val_loss: 0.5236 - val_acc: 0.8211
Epoch 403/500
91s - loss: 0.6923 - acc: 0.7713 - val_loss: 0.5264 - val_acc: 0.8211
Epoch 404/500
91s - loss: 0.6865 - acc: 0.7711 - val_loss: 0.5254 - val_acc: 0.8211
Epoch 405/500
91s - loss: 0.6989 - acc: 0.7603 - val_loss: 0.5232 - val_acc: 0.8232
Epoch 406/500
91s - loss: 0.6798 - acc: 0.7676 - val_loss: 0.5260 - val_acc: 0.8242
Epoch 407/500
91s - loss: 0.6722 - acc: 0.7824 - val_loss: 0.5282 - val_acc: 0.8200
Epoch 408/500
91s - loss: 0.7230 - acc: 0.7616 - val_loss: 0.5247 - val_acc: 0.8221
Epoch 409/500
91s - loss: 0.6923 - acc: 0.7676 - val_loss: 0.5252 - val_acc: 0.8211
Epoch 410/500
91s - loss: 0.6945 - acc: 0.7689 - val_loss: 0.5240 - val_acc: 0.8232
Epoch 411/500
91s - loss: 0.7035 - acc: 0.7689 - val_loss: 0.5255 - val_acc: 0.8232
Epoch 412/500
91s - loss: 0.6746 - acc: 0.7821 - val_loss: 0.5294 - val_acc: 0.8211
Epoch 413/500
91s - loss: 0.6663 - acc: 0.7732 - val_loss: 0.5258 - val_acc: 0.8221
Epoch 414/500
91s - loss: 0.6980 - acc: 0.7684 - val_loss: 0.5256 - val_acc: 0.8232
Epoch 415/500
91s - loss: 0.6609 - acc: 0.7774 - val_loss: 0.5249 - val_acc: 0.8253
Epoch 416/500
91s - loss: 0.6744 - acc: 0.7766 - val_loss: 0.5237 - val_acc: 0.8221
Epoch 417/500
91s - loss: 0.6861 - acc: 0.7650 - val_loss: 0.5236 - val_acc: 0.8232
Epoch 418/500
91s - loss: 0.6736 - acc: 0.7776 - val_loss: 0.5296 - val_acc: 0.8242
Epoch 419/500
91s - loss: 0.6974 - acc: 0.7663 - val_loss: 0.5274 - val_acc: 0.8232
Epoch 420/500
91s - loss: 0.6985 - acc: 0.7726 - val_loss: 0.5231 - val_acc: 0.8232
Epoch 421/500
91s - loss: 0.6738 - acc: 0.7789 - val_loss: 0.5248 - val_acc: 0.8211
Epoch 422/500
91s - loss: 0.6730 - acc: 0.7708 - val_loss: 0.5230 - val_acc: 0.8221
Epoch 423/500
91s - loss: 0.6627 - acc: 0.7745 - val_loss: 0.5256 - val_acc: 0.8221
Epoch 424/500
91s - loss: 0.6644 - acc: 0.7813 - val_loss: 0.5232 - val_acc: 0.8221
Epoch 425/500
91s - loss: 0.6994 - acc: 0.7700 - val_loss: 0.5232 - val_acc: 0.8253
Epoch 426/500
91s - loss: 0.6955 - acc: 0.7632 - val_loss: 0.5233 - val_acc: 0.8232
Epoch 427/500
91s - loss: 0.6729 - acc: 0.7742 - val_loss: 0.5248 - val_acc: 0.8263
Epoch 428/500
91s - loss: 0.6871 - acc: 0.7647 - val_loss: 0.5221 - val_acc: 0.8253
Epoch 429/500
91s - loss: 0.6841 - acc: 0.7671 - val_loss: 0.5263 - val_acc: 0.8242
Epoch 430/500
91s - loss: 0.6812 - acc: 0.7695 - val_loss: 0.5281 - val_acc: 0.8242
Epoch 431/500
91s - loss: 0.6855 - acc: 0.7708 - val_loss: 0.5241 - val_acc: 0.8221
Epoch 432/500
91s - loss: 0.6702 - acc: 0.7729 - val_loss: 0.5244 - val_acc: 0.8274
Epoch 433/500
91s - loss: 0.6783 - acc: 0.7729 - val_loss: 0.5222 - val_acc: 0.8232
Epoch 434/500
91s - loss: 0.6550 - acc: 0.7861 - val_loss: 0.5228 - val_acc: 0.8221
Epoch 435/500
91s - loss: 0.6692 - acc: 0.7692 - val_loss: 0.5225 - val_acc: 0.8232
Epoch 436/500
91s - loss: 0.6601 - acc: 0.7713 - val_loss: 0.5239 - val_acc: 0.8242
Epoch 437/500
91s - loss: 0.6876 - acc: 0.7724 - val_loss: 0.5256 - val_acc: 0.8232
Epoch 438/500
91s - loss: 0.6819 - acc: 0.7747 - val_loss: 0.5249 - val_acc: 0.8253
Epoch 439/500
91s - loss: 0.6769 - acc: 0.7687 - val_loss: 0.5223 - val_acc: 0.8263
Epoch 440/500
91s - loss: 0.6837 - acc: 0.7674 - val_loss: 0.5269 - val_acc: 0.8232
Epoch 441/500
91s - loss: 0.6921 - acc: 0.7721 - val_loss: 0.5299 - val_acc: 0.8253
Epoch 442/500
91s - loss: 0.6812 - acc: 0.7679 - val_loss: 0.5288 - val_acc: 0.8242
Epoch 443/500
91s - loss: 0.7089 - acc: 0.7587 - val_loss: 0.5242 - val_acc: 0.8221
Epoch 444/500
91s - loss: 0.6553 - acc: 0.7787 - val_loss: 0.5265 - val_acc: 0.8253
Epoch 445/500
91s - loss: 0.6693 - acc: 0.7834 - val_loss: 0.5236 - val_acc: 0.8242
Epoch 446/500
91s - loss: 0.7022 - acc: 0.7661 - val_loss: 0.5231 - val_acc: 0.8242
Epoch 447/500
91s - loss: 0.6838 - acc: 0.7732 - val_loss: 0.5227 - val_acc: 0.8263
Epoch 448/500
91s - loss: 0.6705 - acc: 0.7787 - val_loss: 0.5233 - val_acc: 0.8242
Epoch 449/500
91s - loss: 0.6690 - acc: 0.7755 - val_loss: 0.5252 - val_acc: 0.8253
Epoch 450/500
91s - loss: 0.6613 - acc: 0.7834 - val_loss: 0.5209 - val_acc: 0.8253
Epoch 451/500
91s - loss: 0.6610 - acc: 0.7782 - val_loss: 0.5230 - val_acc: 0.8253
Epoch 452/500
91s - loss: 0.6818 - acc: 0.7776 - val_loss: 0.5247 - val_acc: 0.8242
Epoch 453/500
91s - loss: 0.6662 - acc: 0.7763 - val_loss: 0.5238 - val_acc: 0.8253
Epoch 454/500
91s - loss: 0.6564 - acc: 0.7787 - val_loss: 0.5256 - val_acc: 0.8242
Epoch 455/500
91s - loss: 0.6830 - acc: 0.7745 - val_loss: 0.5250 - val_acc: 0.8232
Epoch 456/500
91s - loss: 0.7181 - acc: 0.7645 - val_loss: 0.5233 - val_acc: 0.8242
Epoch 457/500
91s - loss: 0.6674 - acc: 0.7795 - val_loss: 0.5214 - val_acc: 0.8211
Epoch 458/500
91s - loss: 0.6865 - acc: 0.7624 - val_loss: 0.5208 - val_acc: 0.8253
Epoch 459/500
91s - loss: 0.6596 - acc: 0.7763 - val_loss: 0.5251 - val_acc: 0.8253
Epoch 460/500
91s - loss: 0.6940 - acc: 0.7716 - val_loss: 0.5221 - val_acc: 0.8274
Epoch 461/500
91s - loss: 0.6746 - acc: 0.7703 - val_loss: 0.5234 - val_acc: 0.8253
Epoch 462/500
91s - loss: 0.6679 - acc: 0.7797 - val_loss: 0.5204 - val_acc: 0.8263
Epoch 463/500
91s - loss: 0.7146 - acc: 0.7566 - val_loss: 0.5230 - val_acc: 0.8263
Epoch 464/500
91s - loss: 0.6672 - acc: 0.7718 - val_loss: 0.5232 - val_acc: 0.8253
Epoch 465/500
91s - loss: 0.7104 - acc: 0.7676 - val_loss: 0.5209 - val_acc: 0.8221
Epoch 466/500
91s - loss: 0.6885 - acc: 0.7679 - val_loss: 0.5202 - val_acc: 0.8232
Epoch 467/500
91s - loss: 0.6842 - acc: 0.7774 - val_loss: 0.5225 - val_acc: 0.8242
Epoch 468/500
91s - loss: 0.6962 - acc: 0.7761 - val_loss: 0.5233 - val_acc: 0.8253
Epoch 469/500
91s - loss: 0.6615 - acc: 0.7818 - val_loss: 0.5244 - val_acc: 0.8242
Epoch 470/500
91s - loss: 0.6847 - acc: 0.7695 - val_loss: 0.5211 - val_acc: 0.8232
Epoch 471/500
91s - loss: 0.6727 - acc: 0.7726 - val_loss: 0.5233 - val_acc: 0.8242
Epoch 472/500
91s - loss: 0.6841 - acc: 0.7695 - val_loss: 0.5219 - val_acc: 0.8253
Epoch 473/500
91s - loss: 0.6831 - acc: 0.7682 - val_loss: 0.5224 - val_acc: 0.8221
Epoch 474/500
91s - loss: 0.6974 - acc: 0.7700 - val_loss: 0.5223 - val_acc: 0.8253
Epoch 475/500
91s - loss: 0.6755 - acc: 0.7716 - val_loss: 0.5234 - val_acc: 0.8232
Epoch 476/500
91s - loss: 0.6680 - acc: 0.7816 - val_loss: 0.5249 - val_acc: 0.8242
Epoch 477/500
91s - loss: 0.6463 - acc: 0.7779 - val_loss: 0.5278 - val_acc: 0.8211
Epoch 478/500
91s - loss: 0.6643 - acc: 0.7803 - val_loss: 0.5273 - val_acc: 0.8232
Epoch 479/500
91s - loss: 0.6827 - acc: 0.7653 - val_loss: 0.5212 - val_acc: 0.8221
Epoch 480/500
91s - loss: 0.6658 - acc: 0.7774 - val_loss: 0.5192 - val_acc: 0.8253
Epoch 481/500
91s - loss: 0.6892 - acc: 0.7789 - val_loss: 0.5223 - val_acc: 0.8253
Epoch 482/500
91s - loss: 0.6679 - acc: 0.7821 - val_loss: 0.5208 - val_acc: 0.8263
Epoch 483/500
91s - loss: 0.6537 - acc: 0.7737 - val_loss: 0.5215 - val_acc: 0.8232
Epoch 484/500
91s - loss: 0.6658 - acc: 0.7774 - val_loss: 0.5239 - val_acc: 0.8232
Epoch 485/500
91s - loss: 0.6742 - acc: 0.7729 - val_loss: 0.5225 - val_acc: 0.8263
Epoch 486/500
91s - loss: 0.6664 - acc: 0.7761 - val_loss: 0.5216 - val_acc: 0.8263
Epoch 487/500
91s - loss: 0.6746 - acc: 0.7784 - val_loss: 0.5222 - val_acc: 0.8263
Epoch 488/500
91s - loss: 0.6909 - acc: 0.7647 - val_loss: 0.5218 - val_acc: 0.8253
Epoch 489/500
91s - loss: 0.6734 - acc: 0.7687 - val_loss: 0.5206 - val_acc: 0.8232
Epoch 490/500
91s - loss: 0.6723 - acc: 0.7763 - val_loss: 0.5215 - val_acc: 0.8253
Epoch 491/500
91s - loss: 0.6654 - acc: 0.7789 - val_loss: 0.5253 - val_acc: 0.8253
Epoch 492/500
91s - loss: 0.6721 - acc: 0.7713 - val_loss: 0.5231 - val_acc: 0.8263
Epoch 493/500
91s - loss: 0.6723 - acc: 0.7745 - val_loss: 0.5232 - val_acc: 0.8263
Epoch 494/500
91s - loss: 0.6831 - acc: 0.7763 - val_loss: 0.5240 - val_acc: 0.8274
Epoch 495/500
91s - loss: 0.6962 - acc: 0.7634 - val_loss: 0.5220 - val_acc: 0.8263
Epoch 496/500
91s - loss: 0.6836 - acc: 0.7637 - val_loss: 0.5232 - val_acc: 0.8274
Epoch 497/500
91s - loss: 0.6807 - acc: 0.7687 - val_loss: 0.5223 - val_acc: 0.8253
Epoch 498/500
91s - loss: 0.6637 - acc: 0.7787 - val_loss: 0.5239 - val_acc: 0.8242
Epoch 499/500
91s - loss: 0.6953 - acc: 0.7768 - val_loss: 0.5230 - val_acc: 0.8232
Epoch 500/500
91s - loss: 0.6625 - acc: 0.7858 - val_loss: 0.5260 - val_acc: 0.8253
Training loss for fold 0 is 0.3586385214956183 with percent 87.0789473809694
Testing loss for fold 0 is 0.5243533690352189 with percent 82.7368421178115
 
 
Pulling kfold 1 from previous runs
Traceback (most recent call last):
  File "cnn.py", line 94, in <module>
    os.remove(ithSaveStr) # FIX
  File "/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/keras/engine/topology.py", line 2566, in load_weights
    f = h5py.File(filepath, mode='r')
  File "/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/_hl/files.py", line 271, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File "/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/_hl/files.py", line 101, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028130695/work/h5py/_objects.c:2846)
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1490028130695/work/h5py/_objects.c:2804)
  File "h5py/h5f.pyx", line 78, in h5py.h5f.open (/home/ilan/minonda/conda-bld/h5py_1490028130695/work/h5py/h5f.c:2123)
IOError: Unable to open file (Unable to open file: name = 'weights/cnnconv-16-16-32-32-dense-64-64-32-12/imgsize65bsize25split0.2k1.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)
