Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
 
Found train data with correct size
 
 
Found test data with correct size
 
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
Augmentation data size (4750, 2) (794, 2) 2
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
(3800, 65, 65, 3) (3800,)
No saved trial for kfold.
Train on 3800 samples, validate on 950 samples
Epoch 1/500
2018-08-17 14:57:21.789398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-08-17 14:57:21.790153: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
160s - loss: 2.0413 - acc: 0.3082 - val_loss: 2.5240 - val_acc: 0.1874
Epoch 2/500
157s - loss: 1.6570 - acc: 0.4508 - val_loss: 3.6129 - val_acc: 0.2011
Epoch 3/500
157s - loss: 1.4951 - acc: 0.5239 - val_loss: 1.6818 - val_acc: 0.4095
Epoch 4/500
157s - loss: 1.4584 - acc: 0.5297 - val_loss: 2.5438 - val_acc: 0.4937
Epoch 5/500
157s - loss: 1.3602 - acc: 0.5671 - val_loss: 1.2367 - val_acc: 0.6274
Epoch 6/500
157s - loss: 1.2944 - acc: 0.6147 - val_loss: 2.5903 - val_acc: 0.3453
Epoch 7/500
157s - loss: 1.2751 - acc: 0.6121 - val_loss: 1.0311 - val_acc: 0.6663
Epoch 8/500
157s - loss: 1.2134 - acc: 0.6289 - val_loss: 0.9976 - val_acc: 0.7000
Epoch 9/500
157s - loss: 1.1425 - acc: 0.6542 - val_loss: 1.0804 - val_acc: 0.6958
Epoch 10/500
157s - loss: 1.1546 - acc: 0.6587 - val_loss: 1.2364 - val_acc: 0.6242
Epoch 11/500
157s - loss: 1.1739 - acc: 0.6600 - val_loss: 1.3513 - val_acc: 0.6811
Epoch 12/500
157s - loss: 1.1482 - acc: 0.6674 - val_loss: 1.2870 - val_acc: 0.6168
Epoch 13/500
157s - loss: 1.1100 - acc: 0.6853 - val_loss: 2.4709 - val_acc: 0.4179
Epoch 14/500
157s - loss: 1.0326 - acc: 0.6997 - val_loss: 3.1056 - val_acc: 0.5495
Epoch 15/500
157s - loss: 1.0730 - acc: 0.7029 - val_loss: 1.7950 - val_acc: 0.5400
Epoch 16/500
157s - loss: 0.9864 - acc: 0.7258 - val_loss: 1.5378 - val_acc: 0.6884
Epoch 17/500
157s - loss: 1.0536 - acc: 0.7071 - val_loss: 1.8792 - val_acc: 0.5779
Epoch 18/500
157s - loss: 1.0787 - acc: 0.7087 - val_loss: 1.0388 - val_acc: 0.7453
Epoch 19/500
157s - loss: 1.0627 - acc: 0.7182 - val_loss: 3.2506 - val_acc: 0.4326
Epoch 20/500
157s - loss: 1.0360 - acc: 0.7258 - val_loss: 1.0057 - val_acc: 0.7568
Epoch 21/500
157s - loss: 1.0417 - acc: 0.7274 - val_loss: 1.6394 - val_acc: 0.5958
Epoch 22/500
157s - loss: 1.0340 - acc: 0.7329 - val_loss: 2.9206 - val_acc: 0.4158
Epoch 23/500
157s - loss: 1.0462 - acc: 0.7295 - val_loss: 2.5008 - val_acc: 0.5116
Epoch 24/500
157s - loss: 1.0507 - acc: 0.7334 - val_loss: 1.7835 - val_acc: 0.6916
Epoch 25/500
157s - loss: 1.0470 - acc: 0.7389 - val_loss: 1.5566 - val_acc: 0.7189
Epoch 26/500
157s - loss: 1.0721 - acc: 0.7350 - val_loss: 1.2704 - val_acc: 0.7674
Epoch 27/500
157s - loss: 1.0257 - acc: 0.7337 - val_loss: 1.0869 - val_acc: 0.7663
Epoch 28/500
157s - loss: 1.0310 - acc: 0.7521 - val_loss: 1.6679 - val_acc: 0.5884
Epoch 29/500
157s - loss: 1.0056 - acc: 0.7411 - val_loss: 1.5512 - val_acc: 0.6253
Epoch 30/500
157s - loss: 0.9602 - acc: 0.7437 - val_loss: 1.1164 - val_acc: 0.7758
Epoch 31/500
157s - loss: 1.0576 - acc: 0.7374 - val_loss: 1.9467 - val_acc: 0.5979
Epoch 32/500
157s - loss: 1.0754 - acc: 0.7255 - val_loss: 1.0263 - val_acc: 0.7705
Epoch 33/500
157s - loss: 1.0495 - acc: 0.7361 - val_loss: 1.2665 - val_acc: 0.7126
Epoch 34/500
157s - loss: 1.0709 - acc: 0.7455 - val_loss: 1.3113 - val_acc: 0.7537
Epoch 35/500
157s - loss: 1.1052 - acc: 0.7347 - val_loss: 1.4035 - val_acc: 0.7305
Epoch 36/500
157s - loss: 1.0471 - acc: 0.7311 - val_loss: 1.2052 - val_acc: 0.7179
Epoch 37/500
157s - loss: 1.1677 - acc: 0.7071 - val_loss: 0.9472 - val_acc: 0.7453
Epoch 38/500
157s - loss: 1.0577 - acc: 0.7361 - val_loss: 2.0149 - val_acc: 0.5505
Epoch 39/500
157s - loss: 1.1102 - acc: 0.7411 - val_loss: 1.7150 - val_acc: 0.6326
Epoch 40/500
157s - loss: 1.0101 - acc: 0.7558 - val_loss: 2.4700 - val_acc: 0.5884
Epoch 41/500
157s - loss: 1.0802 - acc: 0.7508 - val_loss: 3.1338 - val_acc: 0.3516
Epoch 42/500
157s - loss: 1.1729 - acc: 0.7142 - val_loss: 1.5087 - val_acc: 0.6832
Epoch 43/500

Epoch 00042: reducing learning rate to 0.010000000149.
157s - loss: 1.1613 - acc: 0.7084 - val_loss: 1.2374 - val_acc: 0.6547
Epoch 44/500
157s - loss: 1.0234 - acc: 0.7374 - val_loss: 1.1477 - val_acc: 0.6779
Epoch 45/500
157s - loss: 0.9287 - acc: 0.7434 - val_loss: 1.0040 - val_acc: 0.7126
Epoch 46/500
157s - loss: 0.8740 - acc: 0.7542 - val_loss: 1.0174 - val_acc: 0.7421
Epoch 47/500
157s - loss: 0.8618 - acc: 0.7574 - val_loss: 0.9287 - val_acc: 0.7516
Epoch 48/500
157s - loss: 0.7755 - acc: 0.7668 - val_loss: 0.8894 - val_acc: 0.7411
Epoch 49/500
157s - loss: 0.8444 - acc: 0.7621 - val_loss: 0.8727 - val_acc: 0.7442
Epoch 50/500
157s - loss: 0.8212 - acc: 0.7642 - val_loss: 0.8498 - val_acc: 0.7442
Epoch 51/500
157s - loss: 0.7614 - acc: 0.7726 - val_loss: 0.8277 - val_acc: 0.7421
Epoch 52/500
157s - loss: 0.7486 - acc: 0.7761 - val_loss: 0.8870 - val_acc: 0.7495
Epoch 53/500
157s - loss: 0.7260 - acc: 0.7774 - val_loss: 0.8112 - val_acc: 0.7663
Epoch 54/500
157s - loss: 0.7254 - acc: 0.7742 - val_loss: 0.8682 - val_acc: 0.7463
Epoch 55/500

Epoch 00054: reducing learning rate to 0.000999999977648.
157s - loss: 0.7317 - acc: 0.7805 - val_loss: 0.8271 - val_acc: 0.7547
Epoch 56/500
157s - loss: 0.7187 - acc: 0.7816 - val_loss: 0.7949 - val_acc: 0.7674
Epoch 57/500
157s - loss: 0.7137 - acc: 0.7834 - val_loss: 0.7863 - val_acc: 0.7684
Epoch 58/500
157s - loss: 0.6865 - acc: 0.7876 - val_loss: 0.7816 - val_acc: 0.7726
Epoch 59/500
157s - loss: 0.6791 - acc: 0.7882 - val_loss: 0.7874 - val_acc: 0.7674
Epoch 60/500
157s - loss: 0.6664 - acc: 0.7897 - val_loss: 0.7888 - val_acc: 0.7695
Epoch 61/500
157s - loss: 0.6945 - acc: 0.7929 - val_loss: 0.7798 - val_acc: 0.7747
Epoch 62/500
157s - loss: 0.6825 - acc: 0.7929 - val_loss: 0.7755 - val_acc: 0.7821
Epoch 63/500
157s - loss: 0.7132 - acc: 0.7889 - val_loss: 0.7730 - val_acc: 0.7842
Epoch 64/500
157s - loss: 0.6804 - acc: 0.7953 - val_loss: 0.7625 - val_acc: 0.7895
Epoch 65/500
157s - loss: 0.6886 - acc: 0.7982 - val_loss: 0.7587 - val_acc: 0.7916
Epoch 66/500
157s - loss: 0.7091 - acc: 0.8005 - val_loss: 0.7504 - val_acc: 0.8000
Epoch 67/500
157s - loss: 0.6543 - acc: 0.8016 - val_loss: 0.7618 - val_acc: 0.8000
Epoch 68/500
157s - loss: 0.6851 - acc: 0.8047 - val_loss: 0.7472 - val_acc: 0.8032
Epoch 69/500
157s - loss: 0.6460 - acc: 0.8058 - val_loss: 0.7433 - val_acc: 0.8074
Epoch 70/500
157s - loss: 0.6311 - acc: 0.8134 - val_loss: 0.7519 - val_acc: 0.8095
Epoch 71/500
157s - loss: 0.6350 - acc: 0.8087 - val_loss: 0.7522 - val_acc: 0.8074
Epoch 72/500
157s - loss: 0.6525 - acc: 0.8076 - val_loss: 0.7535 - val_acc: 0.8116
Epoch 73/500
157s - loss: 0.6569 - acc: 0.8132 - val_loss: 0.7569 - val_acc: 0.8084
Epoch 74/500
157s - loss: 0.6657 - acc: 0.8118 - val_loss: 0.7530 - val_acc: 0.8084
Epoch 75/500
157s - loss: 0.6385 - acc: 0.8134 - val_loss: 0.7550 - val_acc: 0.8074
Epoch 76/500
157s - loss: 0.6321 - acc: 0.8150 - val_loss: 0.7328 - val_acc: 0.8189
Epoch 77/500
157s - loss: 0.6549 - acc: 0.8137 - val_loss: 0.7465 - val_acc: 0.8168
Epoch 78/500
157s - loss: 0.6892 - acc: 0.8116 - val_loss: 0.7466 - val_acc: 0.8158
Epoch 79/500
157s - loss: 0.6788 - acc: 0.8084 - val_loss: 0.7553 - val_acc: 0.8189
Epoch 80/500
157s - loss: 0.6498 - acc: 0.8139 - val_loss: 0.7623 - val_acc: 0.8168
Epoch 81/500
157s - loss: 0.5976 - acc: 0.8189 - val_loss: 0.7547 - val_acc: 0.8158
Epoch 82/500
157s - loss: 0.6514 - acc: 0.8200 - val_loss: 0.7445 - val_acc: 0.8200
Epoch 83/500
157s - loss: 0.6641 - acc: 0.8171 - val_loss: 0.7353 - val_acc: 0.8200
Epoch 84/500
157s - loss: 0.6311 - acc: 0.8161 - val_loss: 0.7359 - val_acc: 0.8211
Epoch 85/500
157s - loss: 0.6439 - acc: 0.8168 - val_loss: 0.7383 - val_acc: 0.8189
Epoch 86/500
157s - loss: 0.6395 - acc: 0.8203 - val_loss: 0.7368 - val_acc: 0.8200
Epoch 87/500
157s - loss: 0.6301 - acc: 0.8179 - val_loss: 0.7306 - val_acc: 0.8221
Epoch 88/500
157s - loss: 0.6238 - acc: 0.8203 - val_loss: 0.7266 - val_acc: 0.8221
Epoch 89/500
157s - loss: 0.6566 - acc: 0.8184 - val_loss: 0.7247 - val_acc: 0.8168
Epoch 90/500
157s - loss: 0.6212 - acc: 0.8221 - val_loss: 0.7252 - val_acc: 0.8200
Epoch 91/500
157s - loss: 0.6114 - acc: 0.8226 - val_loss: 0.7126 - val_acc: 0.8232
Epoch 92/500
157s - loss: 0.6272 - acc: 0.8216 - val_loss: 0.7121 - val_acc: 0.8189
Epoch 93/500
157s - loss: 0.6286 - acc: 0.8245 - val_loss: 0.7151 - val_acc: 0.8232
Epoch 94/500
157s - loss: 0.6292 - acc: 0.8237 - val_loss: 0.7028 - val_acc: 0.8242
Epoch 95/500
157s - loss: 0.5925 - acc: 0.8261 - val_loss: 0.6944 - val_acc: 0.8274
Epoch 96/500
157s - loss: 0.5828 - acc: 0.8287 - val_loss: 0.6993 - val_acc: 0.8253
Epoch 97/500
157s - loss: 0.6284 - acc: 0.8266 - val_loss: 0.6946 - val_acc: 0.8263
Epoch 98/500
157s - loss: 0.6377 - acc: 0.8261 - val_loss: 0.6961 - val_acc: 0.8253
Epoch 99/500
157s - loss: 0.6430 - acc: 0.8232 - val_loss: 0.7111 - val_acc: 0.8211
Epoch 100/500
157s - loss: 0.6269 - acc: 0.8282 - val_loss: 0.7048 - val_acc: 0.8211
Epoch 101/500
157s - loss: 0.6242 - acc: 0.8234 - val_loss: 0.6989 - val_acc: 0.8263
Epoch 102/500
157s - loss: 0.6009 - acc: 0.8297 - val_loss: 0.7041 - val_acc: 0.8253
Epoch 103/500
157s - loss: 0.6311 - acc: 0.8268 - val_loss: 0.6923 - val_acc: 0.8274
Epoch 104/500
157s - loss: 0.6000 - acc: 0.8303 - val_loss: 0.6974 - val_acc: 0.8242
Epoch 105/500
157s - loss: 0.5989 - acc: 0.8308 - val_loss: 0.6982 - val_acc: 0.8263
Epoch 106/500
157s - loss: 0.5955 - acc: 0.8316 - val_loss: 0.6977 - val_acc: 0.8263
Epoch 107/500
157s - loss: 0.6048 - acc: 0.8261 - val_loss: 0.6964 - val_acc: 0.8274
Epoch 108/500
157s - loss: 0.5799 - acc: 0.8368 - val_loss: 0.6821 - val_acc: 0.8295
Epoch 109/500
157s - loss: 0.6592 - acc: 0.8263 - val_loss: 0.6908 - val_acc: 0.8253
Epoch 110/500
157s - loss: 0.5936 - acc: 0.8308 - val_loss: 0.6941 - val_acc: 0.8253
Epoch 111/500
157s - loss: 0.5981 - acc: 0.8311 - val_loss: 0.7029 - val_acc: 0.8232
Epoch 112/500
157s - loss: 0.5936 - acc: 0.8329 - val_loss: 0.6991 - val_acc: 0.8274
Epoch 113/500
157s - loss: 0.5816 - acc: 0.8376 - val_loss: 0.6939 - val_acc: 0.8274
Epoch 114/500
157s - loss: 0.5741 - acc: 0.8361 - val_loss: 0.6917 - val_acc: 0.8316
Epoch 115/500
157s - loss: 0.5993 - acc: 0.8289 - val_loss: 0.6914 - val_acc: 0.8284
Epoch 116/500
157s - loss: 0.5775 - acc: 0.8329 - val_loss: 0.6877 - val_acc: 0.8295
Epoch 117/500
157s - loss: 0.5823 - acc: 0.8337 - val_loss: 0.6962 - val_acc: 0.8274
Epoch 118/500
157s - loss: 0.5901 - acc: 0.8334 - val_loss: 0.6949 - val_acc: 0.8305
Epoch 119/500
157s - loss: 0.6268 - acc: 0.8297 - val_loss: 0.6923 - val_acc: 0.8284
Epoch 120/500
157s - loss: 0.6317 - acc: 0.8279 - val_loss: 0.6885 - val_acc: 0.8295
Epoch 121/500
157s - loss: 0.5817 - acc: 0.8400 - val_loss: 0.6940 - val_acc: 0.8305
Epoch 122/500
157s - loss: 0.6197 - acc: 0.8308 - val_loss: 0.6998 - val_acc: 0.8274
Epoch 123/500
157s - loss: 0.6329 - acc: 0.8292 - val_loss: 0.6974 - val_acc: 0.8274
Epoch 124/500
157s - loss: 0.5909 - acc: 0.8316 - val_loss: 0.6940 - val_acc: 0.8284
Epoch 125/500
157s - loss: 0.6218 - acc: 0.8300 - val_loss: 0.6998 - val_acc: 0.8274
Epoch 126/500
157s - loss: 0.5871 - acc: 0.8355 - val_loss: 0.7017 - val_acc: 0.8253
Epoch 127/500

Epoch 00126: reducing learning rate to 9.99999931082e-05.
157s - loss: 0.5770 - acc: 0.8324 - val_loss: 0.6976 - val_acc: 0.8263
Epoch 128/500
