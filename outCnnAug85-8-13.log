Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
 
Found train data with correct size
 
 
Found test data with correct size
 
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
Augmentation data size (4750, 102) (794, 102) 102
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
(3800, 85, 85, 3) (3800,)
No saved trial for kfold.
Train on 3800 samples, validate on 950 samples
Epoch 1/500
2018-08-19 13:02:04.027772: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-08-19 13:02:04.028088: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
325s - loss: 2.0554 - acc: 0.3063 - val_loss: 3.0586 - val_acc: 0.1421
Epoch 2/500
324s - loss: 1.5895 - acc: 0.4855 - val_loss: 2.7773 - val_acc: 0.2547
Epoch 3/500
307s - loss: 1.5144 - acc: 0.5063 - val_loss: 1.6058 - val_acc: 0.5453
Epoch 4/500
300s - loss: 1.4568 - acc: 0.5429 - val_loss: 2.4427 - val_acc: 0.2442
Epoch 5/500
333s - loss: 1.3336 - acc: 0.5884 - val_loss: 1.8106 - val_acc: 0.5600
Epoch 6/500
348s - loss: 1.2732 - acc: 0.6197 - val_loss: 2.5831 - val_acc: 0.3337
Epoch 7/500
311s - loss: 1.2513 - acc: 0.6366 - val_loss: 2.5714 - val_acc: 0.3284
Epoch 8/500
312s - loss: 1.2173 - acc: 0.6355 - val_loss: 5.9953 - val_acc: 0.1884
Epoch 9/500
322s - loss: 1.1493 - acc: 0.6611 - val_loss: 1.8684 - val_acc: 0.5095
Epoch 10/500
324s - loss: 1.1190 - acc: 0.6761 - val_loss: 1.1605 - val_acc: 0.6642
Epoch 11/500
322s - loss: 1.1153 - acc: 0.6897 - val_loss: 1.2151 - val_acc: 0.6958
Epoch 12/500
324s - loss: 1.1148 - acc: 0.6850 - val_loss: 1.3583 - val_acc: 0.6526
Epoch 13/500
319s - loss: 1.1421 - acc: 0.6845 - val_loss: 3.9024 - val_acc: 0.2063
Epoch 14/500
323s - loss: 1.0983 - acc: 0.6995 - val_loss: 2.3057 - val_acc: 0.6042
Epoch 15/500
317s - loss: 1.0739 - acc: 0.7021 - val_loss: 1.2447 - val_acc: 0.7053
Epoch 16/500
317s - loss: 1.1207 - acc: 0.6979 - val_loss: 1.1701 - val_acc: 0.7316
Epoch 17/500
328s - loss: 1.1877 - acc: 0.6958 - val_loss: 1.6324 - val_acc: 0.6042
Epoch 18/500
325s - loss: 1.2275 - acc: 0.6805 - val_loss: 1.2957 - val_acc: 0.7253
Epoch 19/500
332s - loss: 1.1433 - acc: 0.7011 - val_loss: 3.5325 - val_acc: 0.2968
Epoch 20/500
338s - loss: 1.1392 - acc: 0.7100 - val_loss: 1.6870 - val_acc: 0.6832
Epoch 21/500
339s - loss: 1.2302 - acc: 0.7026 - val_loss: 3.9578 - val_acc: 0.5095
Epoch 22/500
341s - loss: 1.1958 - acc: 0.6966 - val_loss: 2.3463 - val_acc: 0.4916
Epoch 23/500
336s - loss: 1.1905 - acc: 0.6866 - val_loss: 1.3337 - val_acc: 0.7084
Epoch 24/500
336s - loss: 1.1801 - acc: 0.6874 - val_loss: 3.2061 - val_acc: 0.3179
Epoch 25/500
340s - loss: 1.2518 - acc: 0.7074 - val_loss: 1.6588 - val_acc: 0.6474
Epoch 26/500
336s - loss: 1.2523 - acc: 0.6689 - val_loss: 1.2889 - val_acc: 0.6189
Epoch 27/500
316s - loss: 1.2735 - acc: 0.6697 - val_loss: 1.9126 - val_acc: 0.6653
Epoch 28/500
323s - loss: 1.1771 - acc: 0.6905 - val_loss: 2.5036 - val_acc: 0.4705
Epoch 29/500

Epoch 00028: reducing learning rate to 0.010000000149.
325s - loss: 1.2666 - acc: 0.6874 - val_loss: 3.7664 - val_acc: 0.3716
Epoch 30/500
331s - loss: 1.1619 - acc: 0.6947 - val_loss: 1.1287 - val_acc: 0.7232
Epoch 31/500
320s - loss: 0.9793 - acc: 0.7289 - val_loss: 1.1233 - val_acc: 0.7411
Epoch 32/500
323s - loss: 0.9573 - acc: 0.7411 - val_loss: 1.1123 - val_acc: 0.7516
Epoch 33/500
335s - loss: 0.8577 - acc: 0.7542 - val_loss: 0.9186 - val_acc: 0.7716
Epoch 34/500
339s - loss: 0.7931 - acc: 0.7724 - val_loss: 0.9478 - val_acc: 0.7705
Epoch 35/500
337s - loss: 0.8016 - acc: 0.7761 - val_loss: 0.9104 - val_acc: 0.7758
Epoch 36/500
339s - loss: 0.7484 - acc: 0.7855 - val_loss: 0.8594 - val_acc: 0.7863
Epoch 37/500
340s - loss: 0.7206 - acc: 0.7974 - val_loss: 0.9512 - val_acc: 0.7926
Epoch 38/500
349s - loss: 0.7036 - acc: 0.7979 - val_loss: 0.9125 - val_acc: 0.7937
Epoch 39/500
338s - loss: 0.7171 - acc: 0.7976 - val_loss: 0.8476 - val_acc: 0.8021
Epoch 40/500
339s - loss: 0.6318 - acc: 0.8061 - val_loss: 0.8416 - val_acc: 0.8011
Epoch 41/500
348s - loss: 0.6610 - acc: 0.8063 - val_loss: 0.7798 - val_acc: 0.8021
Epoch 42/500
336s - loss: 0.6470 - acc: 0.8103 - val_loss: 0.7825 - val_acc: 0.8011
Epoch 43/500
339s - loss: 0.6045 - acc: 0.8211 - val_loss: 0.8157 - val_acc: 0.8000
Epoch 44/500
340s - loss: 0.6418 - acc: 0.8103 - val_loss: 0.7348 - val_acc: 0.8063
Epoch 45/500
347s - loss: 0.5992 - acc: 0.8211 - val_loss: 0.7547 - val_acc: 0.8368
Epoch 46/500
340s - loss: 0.6194 - acc: 0.8234 - val_loss: 0.8476 - val_acc: 0.8147
Epoch 47/500
339s - loss: 0.6026 - acc: 0.8263 - val_loss: 0.7982 - val_acc: 0.8263
Epoch 48/500
341s - loss: 0.5237 - acc: 0.8342 - val_loss: 0.7183 - val_acc: 0.8358
Epoch 49/500
333s - loss: 0.5548 - acc: 0.8434 - val_loss: 0.7502 - val_acc: 0.8484
Epoch 50/500
345s - loss: 0.5539 - acc: 0.8463 - val_loss: 0.7412 - val_acc: 0.8442
Epoch 51/500
342s - loss: 0.5506 - acc: 0.8539 - val_loss: 0.7338 - val_acc: 0.8611
Epoch 52/500
335s - loss: 0.5670 - acc: 0.8489 - val_loss: 0.7843 - val_acc: 0.8442
Epoch 53/500
338s - loss: 0.5676 - acc: 0.8497 - val_loss: 0.7499 - val_acc: 0.8463
Epoch 54/500
338s - loss: 0.5211 - acc: 0.8600 - val_loss: 0.7419 - val_acc: 0.8505
Epoch 55/500
338s - loss: 0.5110 - acc: 0.8611 - val_loss: 0.8611 - val_acc: 0.8411
Epoch 56/500
338s - loss: 0.4914 - acc: 0.8605 - val_loss: 0.8145 - val_acc: 0.8474
Epoch 57/500
338s - loss: 0.5065 - acc: 0.8634 - val_loss: 0.7414 - val_acc: 0.8505
Epoch 58/500
338s - loss: 0.5016 - acc: 0.8626 - val_loss: 0.6513 - val_acc: 0.8600
Epoch 59/500
337s - loss: 0.4804 - acc: 0.8679 - val_loss: 0.7600 - val_acc: 0.8547
Epoch 60/500
338s - loss: 0.4586 - acc: 0.8682 - val_loss: 0.6120 - val_acc: 0.8579
Epoch 61/500
338s - loss: 0.4470 - acc: 0.8700 - val_loss: 0.7104 - val_acc: 0.8674
Epoch 62/500
338s - loss: 0.4420 - acc: 0.8782 - val_loss: 0.7276 - val_acc: 0.8611
Epoch 63/500
338s - loss: 0.4801 - acc: 0.8684 - val_loss: 0.6700 - val_acc: 0.8663
Epoch 64/500
338s - loss: 0.4236 - acc: 0.8824 - val_loss: 0.6912 - val_acc: 0.8611
Epoch 65/500
338s - loss: 0.4555 - acc: 0.8755 - val_loss: 0.7328 - val_acc: 0.8589
Epoch 66/500
338s - loss: 0.4395 - acc: 0.8779 - val_loss: 0.7309 - val_acc: 0.8600
Epoch 67/500
337s - loss: 0.4152 - acc: 0.8821 - val_loss: 0.6522 - val_acc: 0.8589
Epoch 68/500
337s - loss: 0.4045 - acc: 0.8792 - val_loss: 0.6594 - val_acc: 0.8632
Epoch 69/500
338s - loss: 0.4120 - acc: 0.8837 - val_loss: 0.6245 - val_acc: 0.8726
Epoch 70/500
338s - loss: 0.4229 - acc: 0.8776 - val_loss: 0.6624 - val_acc: 0.8600
Epoch 71/500
338s - loss: 0.4201 - acc: 0.8808 - val_loss: 0.6534 - val_acc: 0.8600
Epoch 72/500
338s - loss: 0.4032 - acc: 0.8868 - val_loss: 0.6915 - val_acc: 0.8642
Epoch 73/500
338s - loss: 0.4425 - acc: 0.8826 - val_loss: 0.6555 - val_acc: 0.8716
Epoch 74/500
337s - loss: 0.3923 - acc: 0.8884 - val_loss: 0.6151 - val_acc: 0.8705
Epoch 75/500
338s - loss: 0.3921 - acc: 0.8863 - val_loss: 0.7565 - val_acc: 0.8558
Epoch 76/500
337s - loss: 0.3935 - acc: 0.8903 - val_loss: 0.6664 - val_acc: 0.8674
Epoch 77/500
338s - loss: 0.3822 - acc: 0.8921 - val_loss: 0.7223 - val_acc: 0.8632
Epoch 78/500
338s - loss: 0.3941 - acc: 0.8929 - val_loss: 0.6677 - val_acc: 0.8747
Epoch 79/500
337s - loss: 0.3631 - acc: 0.8976 - val_loss: 0.6648 - val_acc: 0.8653
Epoch 80/500
338s - loss: 0.3740 - acc: 0.8939 - val_loss: 0.6451 - val_acc: 0.8726
Epoch 81/500
336s - loss: 0.3730 - acc: 0.8926 - val_loss: 0.7041 - val_acc: 0.8621
Epoch 82/500
338s - loss: 0.3794 - acc: 0.8958 - val_loss: 0.6534 - val_acc: 0.8716
Epoch 83/500
338s - loss: 0.3841 - acc: 0.8918 - val_loss: 0.6691 - val_acc: 0.8737
Epoch 84/500
338s - loss: 0.3809 - acc: 0.8976 - val_loss: 0.7019 - val_acc: 0.8642
Epoch 85/500
338s - loss: 0.3854 - acc: 0.8929 - val_loss: 0.7136 - val_acc: 0.8642
Epoch 86/500
338s - loss: 0.3792 - acc: 0.8926 - val_loss: 0.6700 - val_acc: 0.8695
Epoch 87/500
337s - loss: 0.3794 - acc: 0.8982 - val_loss: 0.7034 - val_acc: 0.8737
Epoch 88/500
338s - loss: 0.3643 - acc: 0.8958 - val_loss: 0.6792 - val_acc: 0.8747
Epoch 89/500
338s - loss: 0.3686 - acc: 0.8950 - val_loss: 0.6803 - val_acc: 0.8737
Epoch 90/500
338s - loss: 0.3850 - acc: 0.8905 - val_loss: 0.7004 - val_acc: 0.8747
Epoch 91/500

Epoch 00090: reducing learning rate to 0.000999999977648.
338s - loss: 0.3567 - acc: 0.8979 - val_loss: 0.7751 - val_acc: 0.8568
Epoch 92/500
337s - loss: 0.3530 - acc: 0.9047 - val_loss: 0.7325 - val_acc: 0.8705
Epoch 93/500
337s - loss: 0.3793 - acc: 0.8997 - val_loss: 0.7189 - val_acc: 0.8716
Epoch 94/500
338s - loss: 0.3437 - acc: 0.9000 - val_loss: 0.7183 - val_acc: 0.8726
Epoch 95/500
338s - loss: 0.3372 - acc: 0.9026 - val_loss: 0.7079 - val_acc: 0.8716
Epoch 96/500
338s - loss: 0.3365 - acc: 0.9034 - val_loss: 0.6947 - val_acc: 0.8737
Epoch 97/500
338s - loss: 0.3345 - acc: 0.8992 - val_loss: 0.6954 - val_acc: 0.8768
Epoch 98/500
338s - loss: 0.3314 - acc: 0.9042 - val_loss: 0.6974 - val_acc: 0.8768
Epoch 99/500
337s - loss: 0.3412 - acc: 0.9011 - val_loss: 0.6908 - val_acc: 0.8747
Epoch 100/500
337s - loss: 0.3294 - acc: 0.9032 - val_loss: 0.7003 - val_acc: 0.8747
Epoch 101/500
337s - loss: 0.3385 - acc: 0.9037 - val_loss: 0.7002 - val_acc: 0.8758
Epoch 102/500
338s - loss: 0.3148 - acc: 0.9050 - val_loss: 0.7068 - val_acc: 0.8758
Epoch 103/500
337s - loss: 0.3411 - acc: 0.8995 - val_loss: 0.6987 - val_acc: 0.8789
Epoch 104/500
337s - loss: 0.3350 - acc: 0.8976 - val_loss: 0.6954 - val_acc: 0.8747
Epoch 105/500
338s - loss: 0.3326 - acc: 0.9013 - val_loss: 0.7038 - val_acc: 0.8747
Epoch 106/500
337s - loss: 0.3090 - acc: 0.9076 - val_loss: 0.7017 - val_acc: 0.8737
Epoch 107/500
337s - loss: 0.3430 - acc: 0.9029 - val_loss: 0.7085 - val_acc: 0.8747
Epoch 108/500
338s - loss: 0.2937 - acc: 0.9092 - val_loss: 0.7051 - val_acc: 0.8758
Epoch 109/500
338s - loss: 0.3019 - acc: 0.9066 - val_loss: 0.6901 - val_acc: 0.8747
Epoch 110/500
338s - loss: 0.3276 - acc: 0.9026 - val_loss: 0.6994 - val_acc: 0.8747
Epoch 111/500
338s - loss: 0.3506 - acc: 0.9039 - val_loss: 0.7073 - val_acc: 0.8768
Epoch 112/500
338s - loss: 0.3248 - acc: 0.9058 - val_loss: 0.7052 - val_acc: 0.8747
Epoch 113/500
338s - loss: 0.3225 - acc: 0.9066 - val_loss: 0.7055 - val_acc: 0.8758
Epoch 114/500
338s - loss: 0.3002 - acc: 0.9058 - val_loss: 0.7109 - val_acc: 0.8747
Epoch 115/500
337s - loss: 0.3000 - acc: 0.9084 - val_loss: 0.7110 - val_acc: 0.8747
Epoch 116/500

Epoch 00115: reducing learning rate to 9.99999931082e-05.
337s - loss: 0.3249 - acc: 0.9008 - val_loss: 0.7138 - val_acc: 0.8758
Epoch 117/500
338s - loss: 0.3414 - acc: 0.9026 - val_loss: 0.7174 - val_acc: 0.8758
Epoch 118/500
338s - loss: 0.3236 - acc: 0.9050 - val_loss: 0.7094 - val_acc: 0.8758
Epoch 119/500
336s - loss: 0.3306 - acc: 0.9021 - val_loss: 0.7053 - val_acc: 0.8758
Epoch 120/500
338s - loss: 0.3532 - acc: 0.9018 - val_loss: 0.7062 - val_acc: 0.8758
Epoch 121/500
338s - loss: 0.3261 - acc: 0.9039 - val_loss: 0.7119 - val_acc: 0.8758
Training loss for fold 0 is 0.19996816703363468 with percent 93.05263157894737
Testing loss for fold 0 is 0.6987124947497719 with percent 87.89473679191188
 
 
Pulling kfold 1 from previous runs
Training loss for fold 1 is 0.21890743983419317 with percent 93.02631580202203
Testing loss for fold 1 is 0.7794990298622533 with percent 85.78947363401714
 
 
Pulling kfold 2 from previous runs
 
Bad saved trial. Testing acc <0.85%. Rerunning ...
 
Train on 3800 samples, validate on 950 samples
Epoch 1/500
340s - loss: 1.1494 - acc: 0.7495 - val_loss: 2.3061 - val_acc: 0.6674
Epoch 2/500
338s - loss: 1.2186 - acc: 0.7255 - val_loss: 1.9661 - val_acc: 0.6568
Epoch 3/500
338s - loss: 1.3178 - acc: 0.7268 - val_loss: 1.8285 - val_acc: 0.6726
Epoch 4/500
338s - loss: 1.2678 - acc: 0.6839 - val_loss: 1.4568 - val_acc: 0.6695
Epoch 5/500
337s - loss: 1.3965 - acc: 0.6689 - val_loss: 2.6423 - val_acc: 0.2389
Epoch 6/500
338s - loss: 1.3852 - acc: 0.6768 - val_loss: 3.6050 - val_acc: 0.5105
Epoch 7/500
338s - loss: 1.2420 - acc: 0.7195 - val_loss: 2.1472 - val_acc: 0.5926
Epoch 8/500
338s - loss: 1.2455 - acc: 0.7034 - val_loss: 2.6440 - val_acc: 0.6358
Epoch 9/500
337s - loss: 1.2559 - acc: 0.7403 - val_loss: 1.6340 - val_acc: 0.7137
Epoch 10/500
338s - loss: 1.2007 - acc: 0.7382 - val_loss: 2.1652 - val_acc: 0.5432
Epoch 11/500
337s - loss: 1.2855 - acc: 0.7421 - val_loss: 1.6811 - val_acc: 0.7400
Epoch 12/500
337s - loss: 1.4045 - acc: 0.7305 - val_loss: 1.8315 - val_acc: 0.7011
Epoch 13/500
337s - loss: 1.5059 - acc: 0.7313 - val_loss: 1.8262 - val_acc: 0.7505
Epoch 14/500
337s - loss: 1.3750 - acc: 0.7358 - val_loss: 3.2554 - val_acc: 0.2853
Epoch 15/500
337s - loss: 1.3429 - acc: 0.7392 - val_loss: 2.8311 - val_acc: 0.6358
Epoch 16/500
337s - loss: 1.3799 - acc: 0.7450 - val_loss: 2.7066 - val_acc: 0.6305
Epoch 17/500
336s - loss: 1.2933 - acc: 0.7521 - val_loss: 2.1389 - val_acc: 0.6400
Epoch 18/500
337s - loss: 1.3090 - acc: 0.7508 - val_loss: 3.2493 - val_acc: 0.6305
Epoch 19/500
338s - loss: 1.3619 - acc: 0.7476 - val_loss: 2.3247 - val_acc: 0.7179
Epoch 20/500
338s - loss: 1.3570 - acc: 0.7387 - val_loss: 1.9328 - val_acc: 0.6284
Epoch 21/500
337s - loss: 1.2562 - acc: 0.7534 - val_loss: 3.3637 - val_acc: 0.5232
Epoch 22/500
338s - loss: 1.3637 - acc: 0.7392 - val_loss: 5.9649 - val_acc: 0.4421
Epoch 23/500
337s - loss: 1.3492 - acc: 0.7550 - val_loss: 1.8585 - val_acc: 0.5684
Epoch 24/500
337s - loss: 1.4109 - acc: 0.7368 - val_loss: 1.8721 - val_acc: 0.6821
Epoch 25/500
337s - loss: 1.3048 - acc: 0.7550 - val_loss: 2.5811 - val_acc: 0.6842
Epoch 26/500

Epoch 00025: reducing learning rate to 0.010000000149.
337s - loss: 1.3414 - acc: 0.7547 - val_loss: 1.9185 - val_acc: 0.7084
Epoch 27/500
337s - loss: 1.1350 - acc: 0.7624 - val_loss: 1.6006 - val_acc: 0.7400
Epoch 28/500
336s - loss: 1.0776 - acc: 0.7745 - val_loss: 1.5565 - val_acc: 0.7484
Epoch 29/500
338s - loss: 1.1202 - acc: 0.7755 - val_loss: 1.6698 - val_acc: 0.7547
Epoch 30/500
337s - loss: 0.9633 - acc: 0.7945 - val_loss: 1.4727 - val_acc: 0.7653
Epoch 31/500
337s - loss: 0.9396 - acc: 0.7903 - val_loss: 1.5301 - val_acc: 0.7621
Epoch 32/500
337s - loss: 0.8999 - acc: 0.7974 - val_loss: 1.6534 - val_acc: 0.7558
Epoch 33/500
337s - loss: 0.9464 - acc: 0.7945 - val_loss: 1.7744 - val_acc: 0.7537
Epoch 34/500
337s - loss: 0.8950 - acc: 0.7968 - val_loss: 1.7132 - val_acc: 0.7589
Epoch 35/500
337s - loss: 0.9473 - acc: 0.7934 - val_loss: 1.6358 - val_acc: 0.7568
Epoch 36/500
337s - loss: 0.8625 - acc: 0.8047 - val_loss: 1.6925 - val_acc: 0.7537
Epoch 37/500
337s - loss: 0.8738 - acc: 0.7984 - val_loss: 1.5120 - val_acc: 0.7663
Epoch 38/500
337s - loss: 0.8430 - acc: 0.8074 - val_loss: 1.5130 - val_acc: 0.7663
Epoch 39/500
337s - loss: 0.8102 - acc: 0.8097 - val_loss: 1.5547 - val_acc: 0.7716
Epoch 40/500
337s - loss: 0.8276 - acc: 0.8082 - val_loss: 1.6454 - val_acc: 0.7674
Epoch 41/500
337s - loss: 0.8417 - acc: 0.8063 - val_loss: 1.6078 - val_acc: 0.7611
Epoch 42/500
338s - loss: 0.8354 - acc: 0.8100 - val_loss: 1.5435 - val_acc: 0.7653
Epoch 43/500
337s - loss: 0.8183 - acc: 0.8063 - val_loss: 1.4806 - val_acc: 0.7653
Epoch 44/500
337s - loss: 0.8104 - acc: 0.8087 - val_loss: 1.5621 - val_acc: 0.7589
Epoch 45/500
338s - loss: 0.7964 - acc: 0.8118 - val_loss: 1.4560 - val_acc: 0.7716
Epoch 46/500
338s - loss: 0.7428 - acc: 0.8166 - val_loss: 1.4368 - val_acc: 0.7726
Epoch 47/500
338s - loss: 0.7860 - acc: 0.8163 - val_loss: 1.4659 - val_acc: 0.7684
Epoch 48/500
338s - loss: 0.7875 - acc: 0.8166 - val_loss: 1.4023 - val_acc: 0.7758
Epoch 49/500
336s - loss: 0.7724 - acc: 0.8142 - val_loss: 1.4259 - val_acc: 0.7758
Epoch 50/500
337s - loss: 0.7726 - acc: 0.8182 - val_loss: 1.4611 - val_acc: 0.7716
Epoch 51/500
337s - loss: 0.7252 - acc: 0.8192 - val_loss: 1.4561 - val_acc: 0.7705
Epoch 52/500
336s - loss: 0.7753 - acc: 0.8153 - val_loss: 1.4140 - val_acc: 0.7705
Epoch 53/500
337s - loss: 0.6566 - acc: 0.8313 - val_loss: 1.5606 - val_acc: 0.7674
Epoch 54/500
337s - loss: 0.7070 - acc: 0.8208 - val_loss: 1.4544 - val_acc: 0.7758
Epoch 55/500
338s - loss: 0.7171 - acc: 0.8284 - val_loss: 1.4268 - val_acc: 0.7768
Epoch 56/500
337s - loss: 0.7490 - acc: 0.8205 - val_loss: 1.4006 - val_acc: 0.7821
Epoch 57/500
337s - loss: 0.7008 - acc: 0.8208 - val_loss: 1.4156 - val_acc: 0.7842
Epoch 58/500
337s - loss: 0.6928 - acc: 0.8247 - val_loss: 1.4352 - val_acc: 0.7832
Epoch 59/500
337s - loss: 0.7381 - acc: 0.8192 - val_loss: 1.3821 - val_acc: 0.7832
Epoch 60/500
336s - loss: 0.7297 - acc: 0.8266 - val_loss: 1.3605 - val_acc: 0.7726
Epoch 61/500
337s - loss: 0.7079 - acc: 0.8237 - val_loss: 1.3436 - val_acc: 0.7863
Epoch 62/500
336s - loss: 0.6979 - acc: 0.8263 - val_loss: 1.4330 - val_acc: 0.7716
Epoch 63/500
337s - loss: 0.6750 - acc: 0.8268 - val_loss: 1.4746 - val_acc: 0.7726
Epoch 64/500
338s - loss: 0.7197 - acc: 0.8253 - val_loss: 1.3061 - val_acc: 0.7853
Epoch 65/500
337s - loss: 0.7003 - acc: 0.8284 - val_loss: 1.3340 - val_acc: 0.7842
Epoch 66/500
337s - loss: 0.6674 - acc: 0.8276 - val_loss: 1.2409 - val_acc: 0.7863
Epoch 67/500
337s - loss: 0.6454 - acc: 0.8382 - val_loss: 1.1968 - val_acc: 0.7947
Epoch 68/500
337s - loss: 0.6909 - acc: 0.8276 - val_loss: 1.2712 - val_acc: 0.7916
Epoch 69/500
336s - loss: 0.6697 - acc: 0.8311 - val_loss: 1.3651 - val_acc: 0.7800
Epoch 70/500
337s - loss: 0.6356 - acc: 0.8326 - val_loss: 1.2996 - val_acc: 0.7905
Epoch 71/500
336s - loss: 0.6906 - acc: 0.8271 - val_loss: 1.3557 - val_acc: 0.7853
Epoch 72/500
337s - loss: 0.6782 - acc: 0.8332 - val_loss: 1.4048 - val_acc: 0.7874
Epoch 73/500
337s - loss: 0.6546 - acc: 0.8324 - val_loss: 1.2553 - val_acc: 0.7853
Epoch 74/500
337s - loss: 0.6363 - acc: 0.8284 - val_loss: 1.2700 - val_acc: 0.7916
Epoch 75/500
337s - loss: 0.6604 - acc: 0.8313 - val_loss: 1.3457 - val_acc: 0.7863
Epoch 76/500
337s - loss: 0.6816 - acc: 0.8295 - val_loss: 1.4310 - val_acc: 0.7821
Epoch 77/500
337s - loss: 0.6785 - acc: 0.8308 - val_loss: 1.3132 - val_acc: 0.7916
Epoch 78/500
337s - loss: 0.6493 - acc: 0.8324 - val_loss: 1.2251 - val_acc: 0.8000
Epoch 79/500
338s - loss: 0.6342 - acc: 0.8379 - val_loss: 1.3171 - val_acc: 0.8000
Epoch 80/500
337s - loss: 0.6362 - acc: 0.8361 - val_loss: 1.3899 - val_acc: 0.7926
Epoch 81/500
337s - loss: 0.6296 - acc: 0.8426 - val_loss: 1.3033 - val_acc: 0.7968
Epoch 82/500
337s - loss: 0.6294 - acc: 0.8411 - val_loss: 1.3634 - val_acc: 0.8032
Epoch 83/500
337s - loss: 0.6247 - acc: 0.8447 - val_loss: 1.2672 - val_acc: 0.8179
Epoch 84/500
337s - loss: 0.6397 - acc: 0.8497 - val_loss: 1.3624 - val_acc: 0.8095
Epoch 85/500
337s - loss: 0.5744 - acc: 0.8558 - val_loss: 1.3437 - val_acc: 0.8168
Epoch 86/500
337s - loss: 0.6057 - acc: 0.8550 - val_loss: 1.3564 - val_acc: 0.8179
Epoch 87/500
336s - loss: 0.6104 - acc: 0.8595 - val_loss: 1.2946 - val_acc: 0.8253
Epoch 88/500
335s - loss: 0.5744 - acc: 0.8600 - val_loss: 1.3893 - val_acc: 0.8126
Epoch 89/500
333s - loss: 0.6115 - acc: 0.8600 - val_loss: 1.3547 - val_acc: 0.8211
Epoch 90/500
337s - loss: 0.5380 - acc: 0.8682 - val_loss: 1.2851 - val_acc: 0.8253
Epoch 91/500
338s - loss: 0.5430 - acc: 0.8642 - val_loss: 1.3611 - val_acc: 0.8179
Epoch 92/500
337s - loss: 0.5607 - acc: 0.8626 - val_loss: 1.3050 - val_acc: 0.8211
Epoch 93/500
337s - loss: 0.5759 - acc: 0.8613 - val_loss: 1.1474 - val_acc: 0.8295
Epoch 94/500
336s - loss: 0.5816 - acc: 0.8600 - val_loss: 1.1376 - val_acc: 0.8411
Epoch 95/500
337s - loss: 0.5356 - acc: 0.8655 - val_loss: 1.3179 - val_acc: 0.8105
Epoch 96/500
337s - loss: 0.5766 - acc: 0.8616 - val_loss: 1.3926 - val_acc: 0.8147
Epoch 97/500
337s - loss: 0.5684 - acc: 0.8645 - val_loss: 1.2511 - val_acc: 0.8274
Epoch 98/500
337s - loss: 0.6096 - acc: 0.8568 - val_loss: 1.2041 - val_acc: 0.8253
Epoch 99/500
337s - loss: 0.5519 - acc: 0.8653 - val_loss: 1.2301 - val_acc: 0.8200
Epoch 100/500
337s - loss: 0.5242 - acc: 0.8684 - val_loss: 1.1879 - val_acc: 0.8326
Epoch 101/500
337s - loss: 0.5196 - acc: 0.8718 - val_loss: 1.2049 - val_acc: 0.8358
Epoch 102/500
337s - loss: 0.5111 - acc: 0.8700 - val_loss: 1.1334 - val_acc: 0.8421
Epoch 103/500
336s - loss: 0.5722 - acc: 0.8568 - val_loss: 1.1453 - val_acc: 0.8316
Epoch 104/500
337s - loss: 0.5088 - acc: 0.8689 - val_loss: 1.2256 - val_acc: 0.8263
Epoch 105/500
337s - loss: 0.5037 - acc: 0.8692 - val_loss: 1.1804 - val_acc: 0.8274
Epoch 106/500
337s - loss: 0.4848 - acc: 0.8734 - val_loss: 1.1205 - val_acc: 0.8305
Epoch 107/500
337s - loss: 0.5916 - acc: 0.8613 - val_loss: 1.1003 - val_acc: 0.8274
Epoch 108/500
338s - loss: 0.5054 - acc: 0.8713 - val_loss: 1.0789 - val_acc: 0.8368
Epoch 109/500
337s - loss: 0.5331 - acc: 0.8653 - val_loss: 1.1399 - val_acc: 0.8305
Epoch 110/500
337s - loss: 0.5414 - acc: 0.8687 - val_loss: 1.1112 - val_acc: 0.8316
Epoch 111/500
337s - loss: 0.5324 - acc: 0.8626 - val_loss: 1.1781 - val_acc: 0.8368
Epoch 112/500
337s - loss: 0.5188 - acc: 0.8732 - val_loss: 1.1808 - val_acc: 0.8358
Epoch 113/500
337s - loss: 0.4996 - acc: 0.8797 - val_loss: 1.3483 - val_acc: 0.8179
Epoch 114/500
337s - loss: 0.5229 - acc: 0.8776 - val_loss: 1.2542 - val_acc: 0.8263
Epoch 115/500

Epoch 00114: reducing learning rate to 0.000999999977648.
337s - loss: 0.5216 - acc: 0.8797 - val_loss: 1.1636 - val_acc: 0.8326
Epoch 116/500
337s - loss: 0.5061 - acc: 0.8768 - val_loss: 1.1827 - val_acc: 0.8305
Epoch 117/500
337s - loss: 0.4840 - acc: 0.8813 - val_loss: 1.1969 - val_acc: 0.8284
Epoch 118/500
337s - loss: 0.5185 - acc: 0.8739 - val_loss: 1.1784 - val_acc: 0.8326
Epoch 119/500
337s - loss: 0.4805 - acc: 0.8792 - val_loss: 1.2095 - val_acc: 0.8358
Epoch 120/500
337s - loss: 0.4931 - acc: 0.8789 - val_loss: 1.2192 - val_acc: 0.8326
Epoch 121/500
337s - loss: 0.4677 - acc: 0.8855 - val_loss: 1.1548 - val_acc: 0.8358
Epoch 122/500
337s - loss: 0.4760 - acc: 0.8816 - val_loss: 1.2031 - val_acc: 0.8347
Epoch 123/500
337s - loss: 0.4624 - acc: 0.8797 - val_loss: 1.1883 - val_acc: 0.8368
Epoch 124/500
337s - loss: 0.4906 - acc: 0.8808 - val_loss: 1.1489 - val_acc: 0.8379
Epoch 125/500
337s - loss: 0.5095 - acc: 0.8768 - val_loss: 1.1724 - val_acc: 0.8347
Epoch 126/500
337s - loss: 0.4215 - acc: 0.8839 - val_loss: 1.1795 - val_acc: 0.8347
Epoch 127/500

Epoch 00126: reducing learning rate to 9.99999931082e-05.
337s - loss: 0.4759 - acc: 0.8789 - val_loss: 1.1660 - val_acc: 0.8337
Epoch 128/500
337s - loss: 0.4673 - acc: 0.8842 - val_loss: 1.1500 - val_acc: 0.8368
Epoch 129/500
337s - loss: 0.4949 - acc: 0.8776 - val_loss: 1.1692 - val_acc: 0.8368
Epoch 130/500
336s - loss: 0.4220 - acc: 0.8900 - val_loss: 1.1681 - val_acc: 0.8368
Epoch 131/500
337s - loss: 0.4899 - acc: 0.8776 - val_loss: 1.1587 - val_acc: 0.8368
Epoch 132/500
336s - loss: 0.4615 - acc: 0.8853 - val_loss: 1.1906 - val_acc: 0.8347
Epoch 133/500
337s - loss: 0.4558 - acc: 0.8879 - val_loss: 1.1760 - val_acc: 0.8368
Epoch 134/500
337s - loss: 0.4555 - acc: 0.8816 - val_loss: 1.1617 - val_acc: 0.8368
Epoch 135/500
336s - loss: 0.4792 - acc: 0.8797 - val_loss: 1.1707 - val_acc: 0.8358
Epoch 136/500
337s - loss: 0.4844 - acc: 0.8776 - val_loss: 1.1606 - val_acc: 0.8379
Epoch 137/500
337s - loss: 0.4603 - acc: 0.8871 - val_loss: 1.1512 - val_acc: 0.8368
Epoch 138/500
337s - loss: 0.4945 - acc: 0.8782 - val_loss: 1.1730 - val_acc: 0.8368
Epoch 139/500

Epoch 00138: reducing learning rate to 9.99999901978e-06.
336s - loss: 0.4886 - acc: 0.8821 - val_loss: 1.1627 - val_acc: 0.8379
Epoch 140/500
337s - loss: 0.4764 - acc: 0.8808 - val_loss: 1.1483 - val_acc: 0.8368
Epoch 141/500
337s - loss: 0.4789 - acc: 0.8805 - val_loss: 1.1493 - val_acc: 0.8368
Epoch 142/500
337s - loss: 0.5041 - acc: 0.8776 - val_loss: 1.1820 - val_acc: 0.8358
Epoch 143/500
337s - loss: 0.4436 - acc: 0.8884 - val_loss: 1.1649 - val_acc: 0.8368
Epoch 144/500
341s - loss: 0.4753 - acc: 0.8795 - val_loss: 1.1861 - val_acc: 0.8368
Epoch 145/500
340s - loss: 0.4770 - acc: 0.8805 - val_loss: 1.1640 - val_acc: 0.8368
Epoch 146/500
341s - loss: 0.4601 - acc: 0.8813 - val_loss: 1.1676 - val_acc: 0.8368
Epoch 147/500
341s - loss: 0.4971 - acc: 0.8784 - val_loss: 1.1389 - val_acc: 0.8358
Epoch 148/500
341s - loss: 0.4797 - acc: 0.8792 - val_loss: 1.1477 - val_acc: 0.8379
Epoch 149/500
341s - loss: 0.4322 - acc: 0.8863 - val_loss: 1.1510 - val_acc: 0.8368
Epoch 150/500
340s - loss: 0.4532 - acc: 0.8829 - val_loss: 1.1450 - val_acc: 0.8379
Epoch 151/500

Epoch 00150: reducing learning rate to 1e-06.
341s - loss: 0.4582 - acc: 0.8824 - val_loss: 1.1493 - val_acc: 0.8368
Epoch 152/500
341s - loss: 0.4560 - acc: 0.8832 - val_loss: 1.1657 - val_acc: 0.8368
Epoch 153/500
341s - loss: 0.4266 - acc: 0.8900 - val_loss: 1.1672 - val_acc: 0.8368
Epoch 154/500
341s - loss: 0.4352 - acc: 0.8884 - val_loss: 1.1648 - val_acc: 0.8368
Epoch 155/500
341s - loss: 0.4338 - acc: 0.8892 - val_loss: 1.1539 - val_acc: 0.8358
Epoch 156/500
341s - loss: 0.4332 - acc: 0.8853 - val_loss: 1.1681 - val_acc: 0.8368
Epoch 157/500
341s - loss: 0.4613 - acc: 0.8868 - val_loss: 1.1625 - val_acc: 0.8368
Epoch 158/500
341s - loss: 0.4561 - acc: 0.8863 - val_loss: 1.1386 - val_acc: 0.8358
Epoch 159/500
342s - loss: 0.4720 - acc: 0.8866 - val_loss: 1.1481 - val_acc: 0.8379
Epoch 160/500
341s - loss: 0.5014 - acc: 0.8771 - val_loss: 1.1454 - val_acc: 0.8368
Epoch 161/500
342s - loss: 0.4528 - acc: 0.8866 - val_loss: 1.1527 - val_acc: 0.8368
Epoch 162/500
341s - loss: 0.4746 - acc: 0.8797 - val_loss: 1.1446 - val_acc: 0.8379
Epoch 163/500
341s - loss: 0.4977 - acc: 0.8797 - val_loss: 1.1434 - val_acc: 0.8358
Epoch 164/500
341s - loss: 0.4743 - acc: 0.8850 - val_loss: 1.1642 - val_acc: 0.8368
Epoch 165/500
341s - loss: 0.4412 - acc: 0.8876 - val_loss: 1.1651 - val_acc: 0.8358
Epoch 166/500
341s - loss: 0.4297 - acc: 0.8895 - val_loss: 1.1573 - val_acc: 0.8368
Epoch 167/500
341s - loss: 0.4694 - acc: 0.8824 - val_loss: 1.1470 - val_acc: 0.8368
Epoch 168/500
342s - loss: 0.4346 - acc: 0.8829 - val_loss: 1.1586 - val_acc: 0.8368
Epoch 169/500
341s - loss: 0.4651 - acc: 0.8811 - val_loss: 1.1517 - val_acc: 0.8368
Training loss for fold 2 is 0.279589292375665 with percent 91.6842105263158
Testing loss for fold 2 is 1.1333657676922648 with percent 84.2105263785312
 
 
Pulling kfold 3 from previous runs
Training loss for fold 3 is 0.298097831826461 with percent 90.47368419797796
Testing loss for fold 3 is 0.8414023647810284 with percent 85.05263156639901
 
 
Pulling kfold 4 from previous runs
Training loss for fold 4 is 0.2269448920613841 with percent 92.36842104008323
Testing loss for fold 4 is 0.5732633989108237 with percent 87.15789469919707
 
 
Pulling kfold 5 from previous runs
Training loss for fold 5 is 0.2087082771643212 with percent 92.0
Testing loss for fold 5 is 0.5253843980713895 with percent 86.0000000250967
 
 
Pulling kfold 6 from previous runs
Training loss for fold 6 is 0.1784956493503169 with percent 92.42105263157895
Testing loss for fold 6 is 0.6041380255473288 with percent 85.47368427326805
 
 
Pulling kfold 7 from previous runs
Training loss for fold 7 is 0.11585739700613837 with percent 95.36842104008323
Testing loss for fold 7 is 0.5196414727913706 with percent 88.84210528825459
 
 
Pulling kfold 8 from previous runs
Training loss for fold 8 is 0.25033975961961247 with percent 92.28947367166218
Testing loss for fold 8 is 0.8038282273945055 with percent 85.78947373440391
 
No saved trial for kfold.
Train on 3800 samples, validate on 950 samples
Epoch 1/500
355s - loss: 2.1157 - acc: 0.2842 - val_loss: 2.1687 - val_acc: 0.3189
Epoch 2/500
350s - loss: 1.6141 - acc: 0.4700 - val_loss: 1.9623 - val_acc: 0.3505
Epoch 3/500
350s - loss: 1.4809 - acc: 0.5289 - val_loss: 2.9671 - val_acc: 0.3884
Epoch 4/500
348s - loss: 1.3861 - acc: 0.5663 - val_loss: 2.5870 - val_acc: 0.4411
Epoch 5/500
350s - loss: 1.3400 - acc: 0.5921 - val_loss: 1.1958 - val_acc: 0.6347
Epoch 6/500
350s - loss: 1.2923 - acc: 0.6213 - val_loss: 1.5901 - val_acc: 0.4916
Epoch 7/500
350s - loss: 1.2808 - acc: 0.6192 - val_loss: 1.2350 - val_acc: 0.5768
Epoch 8/500
350s - loss: 1.2932 - acc: 0.6376 - val_loss: 1.0900 - val_acc: 0.6674
Epoch 9/500
350s - loss: 1.1867 - acc: 0.6576 - val_loss: 1.8392 - val_acc: 0.5811
Epoch 10/500
350s - loss: 1.1768 - acc: 0.6839 - val_loss: 1.1304 - val_acc: 0.7168
Epoch 11/500
350s - loss: 1.1360 - acc: 0.6861 - val_loss: 1.1819 - val_acc: 0.6579
Epoch 12/500
350s - loss: 1.1893 - acc: 0.6724 - val_loss: 1.1030 - val_acc: 0.7168
Epoch 13/500
351s - loss: 1.1123 - acc: 0.6934 - val_loss: 2.7107 - val_acc: 0.4568
Epoch 14/500
352s - loss: 1.1617 - acc: 0.6803 - val_loss: 1.5251 - val_acc: 0.5095
Epoch 15/500
353s - loss: 1.1205 - acc: 0.6911 - val_loss: 2.5624 - val_acc: 0.5316
Epoch 16/500
352s - loss: 1.0880 - acc: 0.7034 - val_loss: 4.4175 - val_acc: 0.2705
Epoch 17/500
350s - loss: 1.2242 - acc: 0.7045 - val_loss: 2.7912 - val_acc: 0.3653
Epoch 18/500
350s - loss: 1.0666 - acc: 0.7105 - val_loss: 1.0291 - val_acc: 0.7421
Epoch 19/500
350s - loss: 1.0339 - acc: 0.7155 - val_loss: 1.2194 - val_acc: 0.7389
Epoch 20/500
350s - loss: 1.1080 - acc: 0.7097 - val_loss: 1.4906 - val_acc: 0.6989
Epoch 21/500
350s - loss: 1.1063 - acc: 0.7218 - val_loss: 2.0572 - val_acc: 0.5705
Epoch 22/500
350s - loss: 1.1878 - acc: 0.6816 - val_loss: 1.4622 - val_acc: 0.6968
Epoch 23/500
351s - loss: 1.2160 - acc: 0.6963 - val_loss: 4.1949 - val_acc: 0.4242
Epoch 24/500
350s - loss: 1.1535 - acc: 0.7287 - val_loss: 1.5164 - val_acc: 0.6832
Epoch 25/500
351s - loss: 1.1343 - acc: 0.7234 - val_loss: 1.4122 - val_acc: 0.6337
Epoch 26/500
350s - loss: 1.2620 - acc: 0.6874 - val_loss: 1.4045 - val_acc: 0.6484
Epoch 27/500
351s - loss: 1.2651 - acc: 0.6958 - val_loss: 1.7084 - val_acc: 0.6589
Epoch 28/500
353s - loss: 1.2879 - acc: 0.7053 - val_loss: 3.3180 - val_acc: 0.5084
Epoch 29/500
353s - loss: 1.2009 - acc: 0.7132 - val_loss: 3.7491 - val_acc: 0.4611
Epoch 30/500
353s - loss: 1.2310 - acc: 0.7129 - val_loss: 2.0126 - val_acc: 0.6000
Epoch 31/500

Epoch 00030: reducing learning rate to 0.010000000149.
351s - loss: 1.2292 - acc: 0.7016 - val_loss: 1.5006 - val_acc: 0.6316
Epoch 32/500
350s - loss: 1.0519 - acc: 0.7345 - val_loss: 1.2442 - val_acc: 0.7179
Epoch 33/500
351s - loss: 0.9053 - acc: 0.7545 - val_loss: 1.0650 - val_acc: 0.7505
Epoch 34/500
350s - loss: 0.8464 - acc: 0.7805 - val_loss: 1.0481 - val_acc: 0.7726
Epoch 35/500
350s - loss: 0.7954 - acc: 0.7892 - val_loss: 0.9927 - val_acc: 0.7663
Epoch 36/500
343s - loss: 0.8004 - acc: 0.7937 - val_loss: 1.0003 - val_acc: 0.7653
Epoch 37/500
346s - loss: 0.7253 - acc: 0.8082 - val_loss: 0.9738 - val_acc: 0.7737
Epoch 38/500
347s - loss: 0.6875 - acc: 0.8103 - val_loss: 1.0115 - val_acc: 0.7705
Epoch 39/500
347s - loss: 0.7043 - acc: 0.8089 - val_loss: 0.9716 - val_acc: 0.7916
Epoch 40/500
347s - loss: 0.6748 - acc: 0.8174 - val_loss: 0.9631 - val_acc: 0.7747
Epoch 41/500
347s - loss: 0.6929 - acc: 0.8203 - val_loss: 1.0727 - val_acc: 0.7621
Epoch 42/500
346s - loss: 0.6399 - acc: 0.8184 - val_loss: 0.9263 - val_acc: 0.8032
Epoch 43/500
347s - loss: 0.6782 - acc: 0.8208 - val_loss: 1.0089 - val_acc: 0.7916
Epoch 44/500
346s - loss: 0.6452 - acc: 0.8253 - val_loss: 1.0142 - val_acc: 0.7821
Epoch 45/500
346s - loss: 0.6129 - acc: 0.8289 - val_loss: 0.8778 - val_acc: 0.8011
Epoch 46/500
347s - loss: 0.6141 - acc: 0.8332 - val_loss: 0.8577 - val_acc: 0.8189
Epoch 47/500
347s - loss: 0.6315 - acc: 0.8337 - val_loss: 1.0187 - val_acc: 0.8042
Epoch 48/500
347s - loss: 0.5642 - acc: 0.8453 - val_loss: 1.0108 - val_acc: 0.7800
Epoch 49/500
347s - loss: 0.5867 - acc: 0.8432 - val_loss: 0.9124 - val_acc: 0.8074
Epoch 50/500
346s - loss: 0.5587 - acc: 0.8450 - val_loss: 0.9231 - val_acc: 0.7989
Epoch 51/500
346s - loss: 0.6108 - acc: 0.8387 - val_loss: 0.9265 - val_acc: 0.8137
Epoch 52/500
347s - loss: 0.5794 - acc: 0.8389 - val_loss: 0.9500 - val_acc: 0.8042
Epoch 53/500
346s - loss: 0.5413 - acc: 0.8450 - val_loss: 0.9776 - val_acc: 0.7979
Epoch 54/500
347s - loss: 0.5893 - acc: 0.8434 - val_loss: 0.9792 - val_acc: 0.8116
Epoch 55/500
347s - loss: 0.5449 - acc: 0.8487 - val_loss: 0.9396 - val_acc: 0.8211
Epoch 56/500
347s - loss: 0.5621 - acc: 0.8418 - val_loss: 1.0410 - val_acc: 0.7958
Epoch 57/500
345s - loss: 0.5556 - acc: 0.8458 - val_loss: 1.0338 - val_acc: 0.8084
Epoch 58/500
346s - loss: 0.5432 - acc: 0.8518 - val_loss: 0.9239 - val_acc: 0.8189
Epoch 59/500
347s - loss: 0.5434 - acc: 0.8513 - val_loss: 0.9484 - val_acc: 0.8168
Epoch 60/500
346s - loss: 0.5570 - acc: 0.8505 - val_loss: 0.9023 - val_acc: 0.8179
Epoch 61/500
347s - loss: 0.5523 - acc: 0.8487 - val_loss: 0.8047 - val_acc: 0.8179
Epoch 62/500
347s - loss: 0.4894 - acc: 0.8589 - val_loss: 0.8616 - val_acc: 0.8179
Epoch 63/500
347s - loss: 0.5250 - acc: 0.8534 - val_loss: 0.9799 - val_acc: 0.8189
Epoch 64/500
346s - loss: 0.5191 - acc: 0.8576 - val_loss: 0.8892 - val_acc: 0.8168
Epoch 65/500
347s - loss: 0.4965 - acc: 0.8597 - val_loss: 0.9139 - val_acc: 0.8232
Epoch 66/500
347s - loss: 0.5234 - acc: 0.8579 - val_loss: 0.9067 - val_acc: 0.8074
Epoch 67/500
347s - loss: 0.5079 - acc: 0.8605 - val_loss: 0.8439 - val_acc: 0.8211
Epoch 68/500
346s - loss: 0.5067 - acc: 0.8605 - val_loss: 0.7907 - val_acc: 0.8305
Epoch 69/500
347s - loss: 0.5183 - acc: 0.8529 - val_loss: 0.9692 - val_acc: 0.8211
Epoch 70/500
347s - loss: 0.4975 - acc: 0.8616 - val_loss: 0.8783 - val_acc: 0.8126
Epoch 71/500
347s - loss: 0.5109 - acc: 0.8624 - val_loss: 0.8273 - val_acc: 0.8284
Epoch 72/500
347s - loss: 0.5345 - acc: 0.8566 - val_loss: 0.8739 - val_acc: 0.8242
Epoch 73/500
346s - loss: 0.4938 - acc: 0.8618 - val_loss: 0.9999 - val_acc: 0.8137
Epoch 74/500
347s - loss: 0.4900 - acc: 0.8637 - val_loss: 0.8269 - val_acc: 0.8284
Epoch 75/500
347s - loss: 0.4644 - acc: 0.8679 - val_loss: 0.7936 - val_acc: 0.8263
Epoch 76/500
347s - loss: 0.4960 - acc: 0.8626 - val_loss: 0.7911 - val_acc: 0.8284
Epoch 77/500
347s - loss: 0.4957 - acc: 0.8637 - val_loss: 0.8178 - val_acc: 0.8200
Epoch 78/500
347s - loss: 0.4661 - acc: 0.8721 - val_loss: 0.7936 - val_acc: 0.8200
Epoch 79/500
347s - loss: 0.4857 - acc: 0.8637 - val_loss: 0.9560 - val_acc: 0.8095
Epoch 80/500
347s - loss: 0.4592 - acc: 0.8700 - val_loss: 0.7528 - val_acc: 0.8379
Epoch 81/500
347s - loss: 0.4688 - acc: 0.8666 - val_loss: 0.8049 - val_acc: 0.8295
Epoch 82/500
348s - loss: 0.4589 - acc: 0.8679 - val_loss: 0.8502 - val_acc: 0.8337
Epoch 83/500
348s - loss: 0.4639 - acc: 0.8718 - val_loss: 0.8756 - val_acc: 0.8232
Epoch 84/500
347s - loss: 0.4730 - acc: 0.8684 - val_loss: 0.9251 - val_acc: 0.8168
Epoch 85/500
347s - loss: 0.4728 - acc: 0.8711 - val_loss: 1.0323 - val_acc: 0.8189
Epoch 86/500
347s - loss: 0.4710 - acc: 0.8782 - val_loss: 0.7919 - val_acc: 0.8305
Epoch 87/500
347s - loss: 0.4692 - acc: 0.8755 - val_loss: 0.9383 - val_acc: 0.8200
Epoch 88/500
347s - loss: 0.4574 - acc: 0.8742 - val_loss: 0.9098 - val_acc: 0.8126
Epoch 89/500
346s - loss: 0.4691 - acc: 0.8742 - val_loss: 1.0717 - val_acc: 0.8137
Epoch 90/500
347s - loss: 0.4525 - acc: 0.8845 - val_loss: 0.9052 - val_acc: 0.8337
Epoch 91/500
347s - loss: 0.4188 - acc: 0.8863 - val_loss: 0.9420 - val_acc: 0.8316
Epoch 92/500
347s - loss: 0.4638 - acc: 0.8805 - val_loss: 1.1414 - val_acc: 0.8189
Epoch 93/500

Epoch 00092: reducing learning rate to 0.000999999977648.
345s - loss: 0.4014 - acc: 0.8868 - val_loss: 0.8660 - val_acc: 0.8232
Epoch 94/500
347s - loss: 0.4241 - acc: 0.8834 - val_loss: 0.8578 - val_acc: 0.8284
Epoch 95/500
347s - loss: 0.4044 - acc: 0.8863 - val_loss: 0.8634 - val_acc: 0.8316
Epoch 96/500
347s - loss: 0.4210 - acc: 0.8834 - val_loss: 0.8530 - val_acc: 0.8305
Epoch 97/500
346s - loss: 0.3983 - acc: 0.8884 - val_loss: 0.8489 - val_acc: 0.8316
Epoch 98/500
347s - loss: 0.4164 - acc: 0.8913 - val_loss: 0.8714 - val_acc: 0.8326
Epoch 99/500
347s - loss: 0.3923 - acc: 0.8887 - val_loss: 0.8859 - val_acc: 0.8305
Epoch 100/500
347s - loss: 0.4022 - acc: 0.8892 - val_loss: 0.8566 - val_acc: 0.8326
Epoch 101/500
347s - loss: 0.4085 - acc: 0.8874 - val_loss: 0.8555 - val_acc: 0.8295
Epoch 102/500
347s - loss: 0.3818 - acc: 0.8924 - val_loss: 0.8587 - val_acc: 0.8347
Epoch 103/500
347s - loss: 0.4120 - acc: 0.8871 - val_loss: 0.8421 - val_acc: 0.8316
Epoch 104/500
348s - loss: 0.3743 - acc: 0.8900 - val_loss: 0.8216 - val_acc: 0.8337
Epoch 105/500

Epoch 00104: reducing learning rate to 9.99999931082e-05.
348s - loss: 0.3548 - acc: 0.8966 - val_loss: 0.8470 - val_acc: 0.8368
Epoch 106/500
348s - loss: 0.3622 - acc: 0.8950 - val_loss: 0.8425 - val_acc: 0.8347
Epoch 107/500
347s - loss: 0.4024 - acc: 0.8926 - val_loss: 0.8410 - val_acc: 0.8368
Epoch 108/500
347s - loss: 0.4001 - acc: 0.8913 - val_loss: 0.8524 - val_acc: 0.8326
Epoch 109/500
348s - loss: 0.3756 - acc: 0.8937 - val_loss: 0.8324 - val_acc: 0.8337
Epoch 110/500
346s - loss: 0.3639 - acc: 0.8916 - val_loss: 0.8396 - val_acc: 0.8347
Epoch 111/500
346s - loss: 0.3773 - acc: 0.8942 - val_loss: 0.8396 - val_acc: 0.8368
Epoch 112/500
347s - loss: 0.3457 - acc: 0.9000 - val_loss: 0.8373 - val_acc: 0.8368
Epoch 113/500
347s - loss: 0.3932 - acc: 0.8876 - val_loss: 0.8495 - val_acc: 0.8358
Epoch 114/500
348s - loss: 0.3968 - acc: 0.8882 - val_loss: 0.8432 - val_acc: 0.8358
Epoch 115/500
348s - loss: 0.3964 - acc: 0.8895 - val_loss: 0.8387 - val_acc: 0.8358
Epoch 116/500
348s - loss: 0.3848 - acc: 0.8918 - val_loss: 0.8318 - val_acc: 0.8347
Epoch 117/500

Epoch 00116: reducing learning rate to 9.99999901978e-06.
347s - loss: 0.3859 - acc: 0.8939 - val_loss: 0.8494 - val_acc: 0.8358
Epoch 118/500
348s - loss: 0.3967 - acc: 0.8903 - val_loss: 0.8530 - val_acc: 0.8347
Epoch 119/500
347s - loss: 0.3836 - acc: 0.8895 - val_loss: 0.8535 - val_acc: 0.8337
Epoch 120/500
348s - loss: 0.3786 - acc: 0.8924 - val_loss: 0.8530 - val_acc: 0.8368
Epoch 121/500
348s - loss: 0.4151 - acc: 0.8861 - val_loss: 0.8325 - val_acc: 0.8379
Epoch 122/500
347s - loss: 0.3569 - acc: 0.8958 - val_loss: 0.8495 - val_acc: 0.8368
Epoch 123/500
347s - loss: 0.3788 - acc: 0.8913 - val_loss: 0.8306 - val_acc: 0.8358
Epoch 124/500
346s - loss: 0.4067 - acc: 0.8853 - val_loss: 0.8437 - val_acc: 0.8358
Epoch 125/500
347s - loss: 0.3691 - acc: 0.8966 - val_loss: 0.8452 - val_acc: 0.8337
Epoch 126/500
347s - loss: 0.3914 - acc: 0.8903 - val_loss: 0.8599 - val_acc: 0.8316
Epoch 127/500
347s - loss: 0.3517 - acc: 0.8937 - val_loss: 0.8308 - val_acc: 0.8337
Epoch 128/500
348s - loss: 0.3785 - acc: 0.8913 - val_loss: 0.8307 - val_acc: 0.8379
Epoch 129/500

Epoch 00128: reducing learning rate to 1e-06.
345s - loss: 0.3802 - acc: 0.8950 - val_loss: 0.8299 - val_acc: 0.8337
Epoch 130/500
347s - loss: 0.3934 - acc: 0.8911 - val_loss: 0.8391 - val_acc: 0.8368
Epoch 131/500
346s - loss: 0.3682 - acc: 0.8955 - val_loss: 0.8503 - val_acc: 0.8358
Epoch 132/500
348s - loss: 0.3910 - acc: 0.8921 - val_loss: 0.8613 - val_acc: 0.8358
Epoch 133/500
347s - loss: 0.3956 - acc: 0.8879 - val_loss: 0.8472 - val_acc: 0.8368
Epoch 134/500
347s - loss: 0.3889 - acc: 0.8879 - val_loss: 0.8380 - val_acc: 0.8358
Epoch 135/500
347s - loss: 0.3898 - acc: 0.8955 - val_loss: 0.8443 - val_acc: 0.8358
Epoch 136/500
347s - loss: 0.3906 - acc: 0.8889 - val_loss: 0.8407 - val_acc: 0.8368
Epoch 137/500
348s - loss: 0.3935 - acc: 0.8868 - val_loss: 0.8456 - val_acc: 0.8326
Epoch 138/500
347s - loss: 0.3843 - acc: 0.8905 - val_loss: 0.8535 - val_acc: 0.8316
Epoch 139/500
348s - loss: 0.4027 - acc: 0.8895 - val_loss: 0.8366 - val_acc: 0.8368
Epoch 140/500
348s - loss: 0.3927 - acc: 0.8911 - val_loss: 0.8442 - val_acc: 0.8347
Epoch 141/500
347s - loss: 0.4007 - acc: 0.8866 - val_loss: 0.8407 - val_acc: 0.8358
Training loss for fold 9 is 0.25579255527571626 with percent 91.94736840850427
Testing loss for fold 9 is 0.832501758086054 with percent 83.78947370930722
 
Prediction dims (10, 794, 12)
Done training kfolds. Results:
[[0.19996817 0.93052632 0.69871249 0.87894737]
 [0.21890744 0.93026316 0.77949903 0.85789474]
 [0.27958929 0.91684211 1.13336577 0.84210526]
 [0.29809783 0.90473684 0.84140236 0.85052632]
 [0.22694489 0.92368421 0.5732634  0.87157895]
 [0.20870828 0.92       0.5253844  0.86      ]
 [0.17849565 0.92421053 0.60413803 0.85473684]
 [0.1158574  0.95368421 0.51964147 0.88842105]
 [0.25033976 0.92289474 0.80382823 0.85789474]
 [0.25579256 0.91947368 0.83250176 0.83789474]]
