Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
 
Found train data with correct size
 
 
Found test data with correct size
 
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
Augmentation data size (4750, 102) (794, 102) 102
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
(3800, 55, 55, 3) (3800,)
 
Pulling kfold 0 from previous runs
2018-08-17 14:42:02.146813: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-08-17 14:42:02.146837: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
 
Bad saved trial. Testing acc <0.9%. Rerunning ...
 
Train on 3800 samples, validate on 950 samples
Epoch 1/500
111s - loss: 1.4072 - acc: 0.5524 - val_loss: 1.1747 - val_acc: 0.6284
Epoch 2/500
109s - loss: 1.2391 - acc: 0.6139 - val_loss: 3.5890 - val_acc: 0.3937
Epoch 3/500
109s - loss: 1.2066 - acc: 0.6242 - val_loss: 3.2561 - val_acc: 0.2116
Epoch 4/500
109s - loss: 1.1747 - acc: 0.6389 - val_loss: 2.8618 - val_acc: 0.3684
Epoch 5/500
109s - loss: 1.0614 - acc: 0.6861 - val_loss: 7.4536 - val_acc: 0.2253
Epoch 6/500
109s - loss: 1.0497 - acc: 0.6855 - val_loss: 1.4028 - val_acc: 0.6389
Epoch 7/500
109s - loss: 1.0407 - acc: 0.6982 - val_loss: 2.2036 - val_acc: 0.4905
Epoch 8/500
109s - loss: 0.9131 - acc: 0.7297 - val_loss: 2.2539 - val_acc: 0.4979
Epoch 9/500
109s - loss: 0.9048 - acc: 0.7450 - val_loss: 1.3451 - val_acc: 0.6516
Epoch 10/500
109s - loss: 0.9083 - acc: 0.7332 - val_loss: 1.6519 - val_acc: 0.5937
Epoch 11/500
109s - loss: 0.8542 - acc: 0.7576 - val_loss: 1.7992 - val_acc: 0.6442
Epoch 12/500
109s - loss: 0.8419 - acc: 0.7621 - val_loss: 1.7730 - val_acc: 0.6295
Epoch 13/500
109s - loss: 0.8402 - acc: 0.7684 - val_loss: 1.0362 - val_acc: 0.7253
Epoch 14/500
109s - loss: 0.8704 - acc: 0.7529 - val_loss: 1.5049 - val_acc: 0.6716
Epoch 15/500
109s - loss: 0.8328 - acc: 0.7747 - val_loss: 1.0766 - val_acc: 0.7147
Epoch 16/500
109s - loss: 0.7864 - acc: 0.7782 - val_loss: 0.8975 - val_acc: 0.7505
Epoch 17/500
109s - loss: 0.7883 - acc: 0.7782 - val_loss: 1.1856 - val_acc: 0.6611
Epoch 18/500
109s - loss: 0.8045 - acc: 0.7929 - val_loss: 2.4063 - val_acc: 0.5284
Epoch 19/500
109s - loss: 0.7458 - acc: 0.8037 - val_loss: 0.9553 - val_acc: 0.7853
Epoch 20/500
109s - loss: 0.7846 - acc: 0.7945 - val_loss: 1.0090 - val_acc: 0.7684
Epoch 21/500
109s - loss: 0.7730 - acc: 0.7826 - val_loss: 2.4593 - val_acc: 0.5579
Epoch 22/500
109s - loss: 0.7361 - acc: 0.8029 - val_loss: 5.0513 - val_acc: 0.3400
Epoch 23/500
109s - loss: 0.7595 - acc: 0.7847 - val_loss: 2.7031 - val_acc: 0.5032
Epoch 24/500
109s - loss: 0.8134 - acc: 0.7911 - val_loss: 1.2595 - val_acc: 0.7326
Epoch 25/500
109s - loss: 0.7381 - acc: 0.7926 - val_loss: 1.9096 - val_acc: 0.6189
Epoch 26/500
109s - loss: 0.7305 - acc: 0.7950 - val_loss: 0.9934 - val_acc: 0.7958
Epoch 27/500
109s - loss: 0.7515 - acc: 0.7932 - val_loss: 1.3834 - val_acc: 0.7211
Epoch 28/500
108s - loss: 0.8039 - acc: 0.7929 - val_loss: 1.5443 - val_acc: 0.7232
Epoch 29/500
108s - loss: 0.7469 - acc: 0.8139 - val_loss: 1.3319 - val_acc: 0.7274
Epoch 30/500
108s - loss: 0.7263 - acc: 0.8211 - val_loss: 2.2673 - val_acc: 0.6695
Epoch 31/500
108s - loss: 0.7648 - acc: 0.8129 - val_loss: 1.0799 - val_acc: 0.8211
Epoch 32/500
108s - loss: 0.7935 - acc: 0.7974 - val_loss: 0.8519 - val_acc: 0.7716
Epoch 33/500
108s - loss: 0.8084 - acc: 0.8018 - val_loss: 2.1465 - val_acc: 0.6737
Epoch 34/500
108s - loss: 0.6995 - acc: 0.8126 - val_loss: 1.6362 - val_acc: 0.6305
Epoch 35/500
108s - loss: 0.8311 - acc: 0.7918 - val_loss: 1.1424 - val_acc: 0.7884
Epoch 36/500
108s - loss: 0.7486 - acc: 0.8105 - val_loss: 1.4865 - val_acc: 0.7400
Epoch 37/500
108s - loss: 0.8052 - acc: 0.7968 - val_loss: 1.5302 - val_acc: 0.7632
Epoch 38/500
108s - loss: 0.7962 - acc: 0.8203 - val_loss: 2.1396 - val_acc: 0.6895
Epoch 39/500
108s - loss: 0.7814 - acc: 0.8139 - val_loss: 1.8302 - val_acc: 0.6537
Epoch 40/500
108s - loss: 0.7710 - acc: 0.8203 - val_loss: 1.0633 - val_acc: 0.7726
Epoch 41/500
108s - loss: 0.7988 - acc: 0.8000 - val_loss: 2.7254 - val_acc: 0.6695
Epoch 42/500
108s - loss: 0.7304 - acc: 0.8403 - val_loss: 1.4105 - val_acc: 0.7947
Epoch 43/500
108s - loss: 0.7026 - acc: 0.8429 - val_loss: 1.5721 - val_acc: 0.7284
Epoch 44/500

Epoch 00043: reducing learning rate to 0.010000000149.
108s - loss: 0.8068 - acc: 0.8171 - val_loss: 2.1060 - val_acc: 0.6926
Epoch 45/500
108s - loss: 0.6429 - acc: 0.8311 - val_loss: 0.8166 - val_acc: 0.8474
Epoch 46/500
108s - loss: 0.5057 - acc: 0.8592 - val_loss: 0.7884 - val_acc: 0.8484
Epoch 47/500
108s - loss: 0.4542 - acc: 0.8732 - val_loss: 0.8360 - val_acc: 0.8463
Epoch 48/500
108s - loss: 0.4209 - acc: 0.8800 - val_loss: 0.7417 - val_acc: 0.8505
Epoch 49/500
108s - loss: 0.4410 - acc: 0.8842 - val_loss: 0.7779 - val_acc: 0.8632
Epoch 50/500
108s - loss: 0.4274 - acc: 0.8905 - val_loss: 0.7739 - val_acc: 0.8642
Epoch 51/500
108s - loss: 0.3710 - acc: 0.8945 - val_loss: 0.7548 - val_acc: 0.8726
Epoch 52/500
108s - loss: 0.4402 - acc: 0.8908 - val_loss: 0.7026 - val_acc: 0.8779
Epoch 53/500
108s - loss: 0.4275 - acc: 0.8908 - val_loss: 0.7002 - val_acc: 0.8663
Epoch 54/500
108s - loss: 0.3791 - acc: 0.9003 - val_loss: 0.7097 - val_acc: 0.8779
Epoch 55/500
108s - loss: 0.3637 - acc: 0.8966 - val_loss: 0.6537 - val_acc: 0.8695
Epoch 56/500
108s - loss: 0.3377 - acc: 0.9045 - val_loss: 0.6963 - val_acc: 0.8768
Epoch 57/500
108s - loss: 0.3530 - acc: 0.9053 - val_loss: 0.6814 - val_acc: 0.8695
Epoch 58/500
108s - loss: 0.3482 - acc: 0.9029 - val_loss: 0.6888 - val_acc: 0.8747
Epoch 59/500
108s - loss: 0.3384 - acc: 0.9032 - val_loss: 0.6917 - val_acc: 0.8726
Epoch 60/500
108s - loss: 0.3159 - acc: 0.9084 - val_loss: 0.6795 - val_acc: 0.8768
Epoch 61/500
108s - loss: 0.3132 - acc: 0.9089 - val_loss: 0.6904 - val_acc: 0.8663
Epoch 62/500
108s - loss: 0.2946 - acc: 0.9129 - val_loss: 0.6768 - val_acc: 0.8811
Epoch 63/500
107s - loss: 0.3102 - acc: 0.9092 - val_loss: 0.6390 - val_acc: 0.8747
Epoch 64/500
107s - loss: 0.3083 - acc: 0.9089 - val_loss: 0.6818 - val_acc: 0.8800
Epoch 65/500
107s - loss: 0.3010 - acc: 0.9061 - val_loss: 0.7248 - val_acc: 0.8726
Epoch 66/500
107s - loss: 0.3507 - acc: 0.9061 - val_loss: 0.7043 - val_acc: 0.8716
Epoch 67/500
107s - loss: 0.2784 - acc: 0.9124 - val_loss: 0.7729 - val_acc: 0.8674
Epoch 68/500
107s - loss: 0.2841 - acc: 0.9137 - val_loss: 0.7111 - val_acc: 0.8768
Epoch 69/500
107s - loss: 0.2974 - acc: 0.9161 - val_loss: 0.6707 - val_acc: 0.8832
Epoch 70/500
107s - loss: 0.2967 - acc: 0.9103 - val_loss: 0.6652 - val_acc: 0.8779
Epoch 71/500
107s - loss: 0.2932 - acc: 0.9103 - val_loss: 0.6982 - val_acc: 0.8789
Epoch 72/500
107s - loss: 0.2830 - acc: 0.9076 - val_loss: 0.6999 - val_acc: 0.8821
Epoch 73/500
107s - loss: 0.3088 - acc: 0.9055 - val_loss: 0.6812 - val_acc: 0.8800
Epoch 74/500
107s - loss: 0.2693 - acc: 0.9129 - val_loss: 0.6892 - val_acc: 0.8842
Epoch 75/500
107s - loss: 0.2660 - acc: 0.9129 - val_loss: 0.6932 - val_acc: 0.8832
Epoch 76/500
107s - loss: 0.2742 - acc: 0.9142 - val_loss: 0.6725 - val_acc: 0.8863
Epoch 77/500
107s - loss: 0.2743 - acc: 0.9150 - val_loss: 0.7187 - val_acc: 0.8821
Epoch 78/500
107s - loss: 0.2725 - acc: 0.9182 - val_loss: 0.7102 - val_acc: 0.8821
Epoch 79/500
107s - loss: 0.2398 - acc: 0.9229 - val_loss: 0.7174 - val_acc: 0.8842
Epoch 80/500
107s - loss: 0.2828 - acc: 0.9242 - val_loss: 0.7294 - val_acc: 0.8800
Epoch 81/500
107s - loss: 0.2365 - acc: 0.9276 - val_loss: 0.7220 - val_acc: 0.8789
Epoch 82/500
107s - loss: 0.2599 - acc: 0.9197 - val_loss: 0.7214 - val_acc: 0.8821
Epoch 83/500
107s - loss: 0.2706 - acc: 0.9203 - val_loss: 0.7414 - val_acc: 0.8758
Epoch 84/500
107s - loss: 0.2504 - acc: 0.9182 - val_loss: 0.7371 - val_acc: 0.8800
Epoch 85/500
107s - loss: 0.2404 - acc: 0.9239 - val_loss: 0.6938 - val_acc: 0.8800
Epoch 86/500
107s - loss: 0.2452 - acc: 0.9253 - val_loss: 0.6990 - val_acc: 0.8832
Epoch 87/500
107s - loss: 0.2597 - acc: 0.9147 - val_loss: 0.7156 - val_acc: 0.8832
Epoch 88/500
107s - loss: 0.2300 - acc: 0.9239 - val_loss: 0.6882 - val_acc: 0.8853
Epoch 89/500

Epoch 00088: reducing learning rate to 0.000999999977648.
107s - loss: 0.2276 - acc: 0.9268 - val_loss: 0.7056 - val_acc: 0.8737
Epoch 90/500
107s - loss: 0.2413 - acc: 0.9279 - val_loss: 0.6908 - val_acc: 0.8811
Epoch 91/500
107s - loss: 0.2348 - acc: 0.9363 - val_loss: 0.6727 - val_acc: 0.8842
Epoch 92/500
107s - loss: 0.2393 - acc: 0.9279 - val_loss: 0.6796 - val_acc: 0.8789
Epoch 93/500
107s - loss: 0.2291 - acc: 0.9292 - val_loss: 0.6830 - val_acc: 0.8811
Epoch 94/500
107s - loss: 0.2391 - acc: 0.9250 - val_loss: 0.6749 - val_acc: 0.8821
Epoch 95/500
107s - loss: 0.2253 - acc: 0.9287 - val_loss: 0.6726 - val_acc: 0.8853
Epoch 96/500
107s - loss: 0.1990 - acc: 0.9305 - val_loss: 0.6718 - val_acc: 0.8842
Epoch 97/500
107s - loss: 0.2227 - acc: 0.9324 - val_loss: 0.6687 - val_acc: 0.8842
Epoch 98/500
107s - loss: 0.2231 - acc: 0.9300 - val_loss: 0.6767 - val_acc: 0.8842
Epoch 99/500
107s - loss: 0.2246 - acc: 0.9245 - val_loss: 0.6755 - val_acc: 0.8821
Epoch 100/500
107s - loss: 0.2387 - acc: 0.9274 - val_loss: 0.6719 - val_acc: 0.8821
Epoch 101/500

Epoch 00100: reducing learning rate to 9.99999931082e-05.
107s - loss: 0.2353 - acc: 0.9245 - val_loss: 0.6658 - val_acc: 0.8821
Epoch 102/500
107s - loss: 0.2370 - acc: 0.9263 - val_loss: 0.6740 - val_acc: 0.8800
Epoch 103/500
107s - loss: 0.2161 - acc: 0.9287 - val_loss: 0.6655 - val_acc: 0.8811
Epoch 104/500
107s - loss: 0.2184 - acc: 0.9300 - val_loss: 0.6668 - val_acc: 0.8811
Epoch 105/500
107s - loss: 0.2176 - acc: 0.9255 - val_loss: 0.6723 - val_acc: 0.8789
Epoch 106/500
107s - loss: 0.2258 - acc: 0.9326 - val_loss: 0.6709 - val_acc: 0.8811
Epoch 107/500
107s - loss: 0.2317 - acc: 0.9313 - val_loss: 0.6676 - val_acc: 0.8800
Epoch 108/500
107s - loss: 0.2111 - acc: 0.9345 - val_loss: 0.6629 - val_acc: 0.8842
Epoch 109/500
107s - loss: 0.2428 - acc: 0.9242 - val_loss: 0.6720 - val_acc: 0.8842
Epoch 110/500
107s - loss: 0.2237 - acc: 0.9284 - val_loss: 0.6758 - val_acc: 0.8832
Epoch 111/500
107s - loss: 0.2177 - acc: 0.9326 - val_loss: 0.6779 - val_acc: 0.8821
Epoch 112/500
107s - loss: 0.2214 - acc: 0.9353 - val_loss: 0.6705 - val_acc: 0.8853
Epoch 113/500

Epoch 00112: reducing learning rate to 9.99999901978e-06.
107s - loss: 0.2313 - acc: 0.9279 - val_loss: 0.6644 - val_acc: 0.8863
Epoch 114/500
107s - loss: 0.2156 - acc: 0.9308 - val_loss: 0.6732 - val_acc: 0.8842
Epoch 115/500
107s - loss: 0.2227 - acc: 0.9279 - val_loss: 0.6668 - val_acc: 0.8874
Epoch 116/500
107s - loss: 0.2520 - acc: 0.9282 - val_loss: 0.6690 - val_acc: 0.8853
Epoch 117/500
107s - loss: 0.2044 - acc: 0.9366 - val_loss: 0.6822 - val_acc: 0.8842
Epoch 118/500
107s - loss: 0.2333 - acc: 0.9308 - val_loss: 0.6703 - val_acc: 0.8832
Epoch 119/500
107s - loss: 0.2381 - acc: 0.9247 - val_loss: 0.6684 - val_acc: 0.8853
Epoch 120/500
107s - loss: 0.2162 - acc: 0.9321 - val_loss: 0.6698 - val_acc: 0.8853
Epoch 121/500
107s - loss: 0.2016 - acc: 0.9321 - val_loss: 0.6696 - val_acc: 0.8863
Epoch 122/500
107s - loss: 0.2286 - acc: 0.9326 - val_loss: 0.6690 - val_acc: 0.8853
Epoch 123/500
107s - loss: 0.2234 - acc: 0.9316 - val_loss: 0.6760 - val_acc: 0.8842
Epoch 124/500
107s - loss: 0.2267 - acc: 0.9287 - val_loss: 0.6708 - val_acc: 0.8874
Training loss for fold 0 is 0.13447095495305564 with percent 95.1052631704431
Testing loss for fold 0 is 0.6667572837126883 with percent 88.73684209271481
 
No saved trial for kfold.
Train on 3800 samples, validate on 950 samples
Epoch 1/500
111s - loss: 2.0016 - acc: 0.3226 - val_loss: 1.7590 - val_acc: 0.3316
Epoch 2/500
108s - loss: 1.4839 - acc: 0.5189 - val_loss: 1.2044 - val_acc: 0.6011
Epoch 3/500
108s - loss: 1.3406 - acc: 0.5787 - val_loss: 5.5904 - val_acc: 0.3011
Epoch 4/500
108s - loss: 1.2278 - acc: 0.6116 - val_loss: 1.2591 - val_acc: 0.6158
Epoch 5/500
108s - loss: 1.1759 - acc: 0.6432 - val_loss: 2.0589 - val_acc: 0.5432
Epoch 6/500
108s - loss: 1.1053 - acc: 0.6711 - val_loss: 1.4176 - val_acc: 0.6074
Epoch 7/500
108s - loss: 1.0749 - acc: 0.6903 - val_loss: 2.5692 - val_acc: 0.4242
Epoch 8/500
108s - loss: 1.0138 - acc: 0.7026 - val_loss: 1.6712 - val_acc: 0.5916
Epoch 9/500
107s - loss: 0.9550 - acc: 0.7132 - val_loss: 9.2182 - val_acc: 0.1221
Epoch 10/500
107s - loss: 0.9717 - acc: 0.7171 - val_loss: 0.9582 - val_acc: 0.7568
Epoch 11/500
107s - loss: 0.9056 - acc: 0.7408 - val_loss: 0.9552 - val_acc: 0.7305
Epoch 12/500
107s - loss: 0.8598 - acc: 0.7597 - val_loss: 2.5705 - val_acc: 0.5274
Epoch 13/500
107s - loss: 0.8736 - acc: 0.7497 - val_loss: 2.7288 - val_acc: 0.4126
Epoch 14/500
107s - loss: 0.8278 - acc: 0.7716 - val_loss: 1.3561 - val_acc: 0.6884
Epoch 15/500
107s - loss: 0.8092 - acc: 0.7737 - val_loss: 1.2106 - val_acc: 0.7053
Epoch 16/500
107s - loss: 0.7896 - acc: 0.7768 - val_loss: 0.9362 - val_acc: 0.7768
Epoch 17/500
107s - loss: 0.7394 - acc: 0.7892 - val_loss: 1.8642 - val_acc: 0.5463
Epoch 18/500
107s - loss: 0.7744 - acc: 0.7900 - val_loss: 2.4174 - val_acc: 0.5337
Epoch 19/500
107s - loss: 0.7277 - acc: 0.7918 - val_loss: 1.5630 - val_acc: 0.6958
Epoch 20/500
107s - loss: 0.7484 - acc: 0.7963 - val_loss: 2.1191 - val_acc: 0.4789
Epoch 21/500
107s - loss: 0.7311 - acc: 0.8029 - val_loss: 0.8837 - val_acc: 0.7863
Epoch 22/500
107s - loss: 0.7219 - acc: 0.8066 - val_loss: 1.3657 - val_acc: 0.7716
Epoch 23/500
107s - loss: 0.7073 - acc: 0.8029 - val_loss: 0.8382 - val_acc: 0.7326
Epoch 24/500
107s - loss: 0.7106 - acc: 0.8074 - val_loss: 1.1597 - val_acc: 0.7579
Epoch 25/500
107s - loss: 0.6898 - acc: 0.8079 - val_loss: 1.2165 - val_acc: 0.7179
Epoch 26/500
107s - loss: 0.6864 - acc: 0.8232 - val_loss: 2.0161 - val_acc: 0.6137
Epoch 27/500
107s - loss: 0.6887 - acc: 0.8139 - val_loss: 3.2998 - val_acc: 0.4789
Epoch 28/500
107s - loss: 0.6177 - acc: 0.8245 - val_loss: 1.1022 - val_acc: 0.7789
Epoch 29/500
107s - loss: 0.6336 - acc: 0.8274 - val_loss: 3.3381 - val_acc: 0.5147
Epoch 30/500
107s - loss: 0.6191 - acc: 0.8332 - val_loss: 1.1043 - val_acc: 0.7716
Epoch 31/500
107s - loss: 0.6376 - acc: 0.8261 - val_loss: 0.8962 - val_acc: 0.7863
Epoch 32/500
107s - loss: 0.6686 - acc: 0.8300 - val_loss: 1.9592 - val_acc: 0.7179
Epoch 33/500
107s - loss: 0.6908 - acc: 0.8297 - val_loss: 1.3230 - val_acc: 0.7453
Epoch 34/500

Epoch 00033: reducing learning rate to 0.010000000149.
107s - loss: 0.6698 - acc: 0.8358 - val_loss: 2.1029 - val_acc: 0.5400
Epoch 35/500
107s - loss: 0.5081 - acc: 0.8553 - val_loss: 0.6866 - val_acc: 0.8379
Epoch 36/500
107s - loss: 0.3941 - acc: 0.8805 - val_loss: 0.6486 - val_acc: 0.8526
Epoch 37/500
107s - loss: 0.3477 - acc: 0.8924 - val_loss: 0.6103 - val_acc: 0.8674
Epoch 38/500
107s - loss: 0.3439 - acc: 0.8861 - val_loss: 0.6028 - val_acc: 0.8611
Epoch 39/500
107s - loss: 0.3260 - acc: 0.8953 - val_loss: 0.5994 - val_acc: 0.8600
Epoch 40/500
107s - loss: 0.3195 - acc: 0.8958 - val_loss: 0.5782 - val_acc: 0.8600
Epoch 41/500
108s - loss: 0.2945 - acc: 0.9034 - val_loss: 0.5846 - val_acc: 0.8737
Epoch 42/500
107s - loss: 0.2732 - acc: 0.9047 - val_loss: 0.6012 - val_acc: 0.8674
Epoch 43/500
107s - loss: 0.2701 - acc: 0.9121 - val_loss: 0.6008 - val_acc: 0.8642
Epoch 44/500
107s - loss: 0.2812 - acc: 0.9066 - val_loss: 0.6394 - val_acc: 0.8547
Epoch 45/500
107s - loss: 0.2811 - acc: 0.9105 - val_loss: 0.6116 - val_acc: 0.8558
Epoch 46/500
107s - loss: 0.2534 - acc: 0.9103 - val_loss: 0.5889 - val_acc: 0.8653
Epoch 47/500
107s - loss: 0.2544 - acc: 0.9076 - val_loss: 0.5525 - val_acc: 0.8821
Epoch 48/500
107s - loss: 0.2545 - acc: 0.9084 - val_loss: 0.6413 - val_acc: 0.8653
Epoch 49/500
107s - loss: 0.2543 - acc: 0.9174 - val_loss: 0.6767 - val_acc: 0.8684
Epoch 50/500
107s - loss: 0.2445 - acc: 0.9168 - val_loss: 0.5976 - val_acc: 0.8642
Epoch 51/500
107s - loss: 0.2345 - acc: 0.9200 - val_loss: 0.5844 - val_acc: 0.8779
Epoch 52/500
107s - loss: 0.2552 - acc: 0.9166 - val_loss: 0.6046 - val_acc: 0.8663
Epoch 53/500
107s - loss: 0.2520 - acc: 0.9161 - val_loss: 0.5978 - val_acc: 0.8726
Epoch 54/500
107s - loss: 0.2380 - acc: 0.9216 - val_loss: 0.6002 - val_acc: 0.8768
Epoch 55/500
107s - loss: 0.2199 - acc: 0.9221 - val_loss: 0.6389 - val_acc: 0.8737
Epoch 56/500
107s - loss: 0.2115 - acc: 0.9255 - val_loss: 0.5615 - val_acc: 0.8874
Epoch 57/500
107s - loss: 0.2108 - acc: 0.9239 - val_loss: 0.5811 - val_acc: 0.8737
Epoch 58/500
107s - loss: 0.2246 - acc: 0.9218 - val_loss: 0.6180 - val_acc: 0.8853
Epoch 59/500
107s - loss: 0.2113 - acc: 0.9282 - val_loss: 0.6203 - val_acc: 0.8768
Epoch 60/500
107s - loss: 0.2190 - acc: 0.9284 - val_loss: 0.6297 - val_acc: 0.8705
Epoch 61/500
107s - loss: 0.2147 - acc: 0.9295 - val_loss: 0.6014 - val_acc: 0.8832
Epoch 62/500
107s - loss: 0.2049 - acc: 0.9276 - val_loss: 0.6095 - val_acc: 0.8853
Epoch 63/500
107s - loss: 0.2097 - acc: 0.9324 - val_loss: 0.6199 - val_acc: 0.8789
Epoch 64/500
107s - loss: 0.2070 - acc: 0.9334 - val_loss: 0.6264 - val_acc: 0.8789
Epoch 65/500
107s - loss: 0.2056 - acc: 0.9324 - val_loss: 0.6081 - val_acc: 0.8779
Epoch 66/500
107s - loss: 0.1868 - acc: 0.9366 - val_loss: 0.7073 - val_acc: 0.8747
Epoch 67/500
107s - loss: 0.2015 - acc: 0.9303 - val_loss: 0.6516 - val_acc: 0.8716
Epoch 68/500
107s - loss: 0.2043 - acc: 0.9300 - val_loss: 0.6936 - val_acc: 0.8758
Epoch 69/500
